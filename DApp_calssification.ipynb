{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DApp_calssification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3paWtjVD4Gd",
        "colab_type": "code",
        "outputId": "48df4b99-e34a-4d90-e53a-60d58e79ee71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnuPCxHGL7C",
        "colab_type": "code",
        "outputId": "73c89ee9-eae9-40b3-ac63-ab3be4031118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import nltk\n",
        "dler = nltk.downloader.Downloader()\n",
        "dler._update_index()\n",
        "dler.download('all')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-JK4yXs4SZx",
        "colab_type": "text"
      },
      "source": [
        "# File loading, Train-test-split, result table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I21OjFQf2rOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.sparse import hstack\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "seed = int(time.strftime(\"%Y%m%d\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw03WHmJELWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/sol_classification.pickle'\n",
        "data = pickle.load(open(path, \"rb\"))\n",
        "data.comments = data.comments.apply('\\n'.join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEFcrwfXa0dl",
        "colab_type": "code",
        "outputId": "08dbb116-c9b2-4ad2-9607-ea5ef6f7e959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2124 entries, 0 to 2123\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   source_code  2124 non-null   object\n",
            " 1   uncommented  2124 non-null   object\n",
            " 2   comments     2124 non-null   object\n",
            " 3   category     2124 non-null   object\n",
            "dtypes: object(4)\n",
            "memory usage: 83.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJoPpvoM4rlh",
        "colab_type": "code",
        "outputId": "bd37aeb3-da51-453d-bebe-9d4ffc7944b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# suppress categories with freq less than 2%\n",
        "freq = data['category'].value_counts(normalize=True)\n",
        "data['category'].replace(to_replace=list(freq[freq<0.02].index),value='others',inplace=True)\n",
        "data['category'].value_counts(normalize=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "games           0.268832\n",
              "exchanges       0.216102\n",
              "finance         0.156309\n",
              "gambling        0.093691\n",
              "others          0.056026\n",
              "high-risk       0.044727\n",
              "marketplaces    0.039077\n",
              "social          0.036723\n",
              "development     0.033427\n",
              "media           0.031544\n",
              "property        0.023540\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjJlAu8lFuZc",
        "colab_type": "code",
        "outputId": "3b3124e4-10f1-44b3-80d6-3427f2c45c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# dummy coding for target variables\n",
        "dummies = data['category'].str.get_dummies()\n",
        "X = data.loc[:,('source_code','uncommented','comments')]\n",
        "dummies.shape, X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2124, 11), (2124, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0BZeVlgxSGn",
        "colab_type": "code",
        "outputId": "74a11a66-6cdc-4059-81c5-957f0934bf75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, dummies, test_size = 0.25, random_state = seed, stratify=data.category)\n",
        "Y_train_labels = Y_train.idxmax(axis=1)\n",
        "Y_test_labels = Y_test.idxmax(axis=1)\n",
        "\n",
        "label_coder = LabelEncoder()\n",
        "Y_train_labels = label_coder.fit_transform(Y_train_labels)\n",
        "Y_test_labels = label_coder.transform(Y_test_labels)\n",
        "\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape, Y_train_labels.shape, Y_test_labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1593, 3), (531, 3), (1593, 11), (531, 11), (1593,), (531,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2v6r7A79o85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initiate result matrixs for cv and the test set\n",
        "\n",
        "iterables = [['punctuations_removed', 'punctuations_preserved'], #input type\n",
        "        ['logit','lightbm','mlp','GRU','CNN'], #model types  \n",
        "        data['category'].value_counts().index, #category\n",
        "        ] \n",
        "\n",
        "index = pd.MultiIndex.from_product(iterables, names=['input_types','models','categories'])\n",
        "result = pd.DataFrame(index=index)\n",
        "result['AUC'] = None\n",
        "result.reset_index(inplace=True)\n",
        "cv_result = result.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMOFBAI3xH7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.read_csv('H2_test.csv')\n",
        "cv_result = pd.read_csv('H2_validation.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW7yAaQRuQXZ",
        "colab_type": "text"
      },
      "source": [
        "# Non-NLP\n",
        "length of comments, length of codes and the comment/code ratio\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgQPnaPCrdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def X_non_NLP_features (X):\n",
        "  code_len = X['uncommented'].apply(lambda x: len([line for line in x.split('\\n') if line.strip() != '']))\n",
        "  X = X.assign(code_len = code_len)\n",
        "\n",
        "  comment_len = X['comments'].apply(lambda x: len([line for line in x.split('\\n') if line.strip() != '']))\n",
        "  X = X.assign(comment_len = comment_len)\n",
        "\n",
        "  comment_ratio = comment_len/code_len\n",
        "  X = X.assign(comment_ratio = comment_ratio)\n",
        "\n",
        "  X.drop(labels=['source_code','uncommented','comments'],axis=1,inplace=True)\n",
        "  return np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9etCIKuV-e",
        "colab_type": "text"
      },
      "source": [
        "# BOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZc49Ht8IFef",
        "colab_type": "text"
      },
      "source": [
        "## BOW tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqHX66AkFfnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NLP imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tc2ekJuQVkAc",
        "colab": {}
      },
      "source": [
        "my_stopwords = stopwords.words(\"english\")\n",
        "my_stopwords.append(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs-Ti5IMJiSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check out the first 20 comments as a sample for tokenizing\n",
        "regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "corpus = ' '.join(X_train[0:20]['comments'].values)\n",
        "new_words = regex_tokenizer.tokenize(corpus)\n",
        "\n",
        "new_words = sum([word.split('_') for word in new_words],[])\n",
        "new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words] #split cramelCase\n",
        "new_words = sum(new_words, [])\n",
        "\n",
        "fdist1 = nltk.FreqDist(new_words)\n",
        "fdist1.most_common(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZwEVle4pEWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer_comments (text):\n",
        "  \n",
        "  #tokenize\n",
        "  regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "  new_words = regex_tokenizer.tokenize(text)\n",
        "\n",
        "  #remove numbers\n",
        "  new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "\n",
        "  #split additionally by under_score\n",
        "  new_words = sum([word.split('_') for word in new_words],[])\n",
        "\n",
        "  #clear camelCase\n",
        "  new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words]\n",
        "  new_words = sum(new_words, [])\n",
        "\n",
        "  return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRWuO6FLb5xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer_codes (text):\n",
        "  \n",
        "  #tokenize\n",
        "  new_words = nltk.word_tokenize(text)\n",
        "\n",
        "  #remove numbers\n",
        "  new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "\n",
        "  #split additionally by under_score\n",
        "  new_words = sum([word.split('_') for word in new_words],[])\n",
        "\n",
        "  #clear camelCase\n",
        "  new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words]\n",
        "  new_words = sum(new_words, [])\n",
        "\n",
        "  return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjml85NG6Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_comments = TfidfVectorizer(stop_words = my_stopwords, tokenizer = tokenizer_comments, lowercase = True,\n",
        "                max_features=5000, smooth_idf=True, analyzer = 'word')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOnzKuQEcsGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_codes = TfidfVectorizer(stop_words = my_stopwords, tokenizer = tokenizer_codes, lowercase = True,\n",
        "                max_features=5000, smooth_idf=True, analyzer = 'word')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54d7sYVEjyTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer_combined = TfidfVectorizer(stop_words = my_stopwords, tokenizer = tokenizer_codes, lowercase = True,\n",
        "                max_features=10000, smooth_idf=True, analyzer = 'word')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd4blqlM6RY4",
        "colab_type": "text"
      },
      "source": [
        "## Models based on BOW: logit, lightbm, multilayer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDFmD09rAdfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/params_search.pickle'\n",
        "DApps_model_params = pickle.load(open(path, \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va_dS0D0dfz-",
        "colab_type": "text"
      },
      "source": [
        "Define models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F3FuvDUC37Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logit model\n",
        "def logit_model (X_train,y_train,params):\n",
        "  #logreg = LogisticRegression(penalty=params['penalty'],max_iter=1000)\n",
        "  logreg = LogisticRegression(penalty=params['penalty'],C=params['C'],max_iter=10000)\n",
        "  logreg.fit(X_train, y_train)\n",
        "  return logreg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHWleBX7j6Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lightbm model\n",
        "def lightbm_model (X_train,y_train,params):\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = seed, stratify=y_train)\n",
        "\n",
        "  train_data = lgb.Dataset(X_train,label=y_train)\n",
        "  validation_data = lgb.Dataset(X_val,label=y_val)\n",
        "\n",
        "  params.update([('objective','binary'),('metric','auc')])\n",
        "  num_round = 100\n",
        "  bst = lgb.train(params, train_data, num_round, valid_sets=validation_data,verbose_eval=False,early_stopping_rounds=5)\n",
        "\n",
        "  return bst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfie5pcv_XDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model (X_train,y_train,params):\n",
        "  mlp_classifier = MLPClassifier(hidden_layer_sizes=params['hidden_layer_sizes'],solver=params['solver'],early_stopping=True,max_iter=10000)\n",
        "  mlp_classifier.fit(X_train, y_train)\n",
        "  return mlp_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG_vvcysdi85",
        "colab_type": "text"
      },
      "source": [
        "Cross-validation with params search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn8XCUpTuFz7",
        "colab_type": "code",
        "outputId": "994239c9-9c42-4efd-ef50-0b9537231416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# cross_validation for opt params\n",
        "DApps_model_params = {}\n",
        "DApps_model_score = {}\n",
        "for DApp_type in data['category'].value_counts().index:\n",
        "  print(\"Category:\", DApp_type)\n",
        "  y_train = np.array(Y_train[DApp_type])\n",
        "\n",
        "  #X_train_NLP = vectorizer_comments.fit_transform(X_train['comments'])\n",
        "  #X_train_NLP = vectorizer_codes.fit_transform(X_train['uncommented'])\n",
        "  X_train_NLP = vectorizer_combined.fit_transform(X_train['source_code'])\n",
        "\n",
        "  X_train_CV = X_train_NLP\n",
        "\n",
        "  scaler = MaxAbsScaler()\n",
        "  X_train_CV = scaler.fit_transform(X_train_CV)\n",
        "\n",
        "  params_dist = {'logit':{'penalty':['l2'],'C':[0.25,0.5,1]},\n",
        "           'lightbm':{'num_leaves':[64, 128, 256]},\n",
        "           'mlp':{'hidden_layer_sizes':[(64,32),(128,32),(256,32)],\n",
        "               'solver':['adam'],\n",
        "               'n_iter_no_change':[3]}}\n",
        "\n",
        "  print('Fitting logit')\n",
        "  logit_classifier = LogisticRegression(max_iter=10000)\n",
        "  logit_search = RandomizedSearchCV(logit_classifier, param_distributions=params_dist['logit'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=1, verbose=0)\n",
        "  logit_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  print('Fitting lightbm')\n",
        "  lgb_classifier = lgb.LGBMClassifier()\n",
        "  #lgb_search = GridSearchCV(lgb_classifier, param_grid=params_dist['lightbm'], cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  lgb_search = RandomizedSearchCV(lgb_classifier, param_distributions=params_dist['lightbm'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=1, verbose=0)\n",
        "  lgb_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  print('Fitting MLP')\n",
        "  mlp_classifier = MLPClassifier(early_stopping=True,max_iter=10000)\n",
        "  #mlp_search = GridSearchCV(mlp_classifier, param_grid=params_dist['mlp'], cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  mlp_search = RandomizedSearchCV(mlp_classifier, param_distributions=params_dist['mlp'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=1, verbose=0)\n",
        "  mlp_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  searches = {'logit_params':logit_search.best_params_,'lgb_params':lgb_search.best_params_,'mlp_params':mlp_search.best_params_}\n",
        "  DApps_model_params.update([(DApp_type,searches)])\n",
        "  scores = {'logit_score':logit_search.best_score_,'lgb_score':lgb_search.best_score_,'mlp_score':mlp_search.best_score_}\n",
        "  DApps_model_score.update([(DApp_type,scores)])\n",
        "\n",
        "with open('params_search.pickle', 'wb') as handle:\n",
        "  pickle.dump(DApps_model_params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category: games\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: exchanges\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: finance\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: gambling\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: others\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: high-risk\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: marketplaces\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: social\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: development\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: media\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n",
            "Category: property\n",
            "Fitting logit\n",
            "Fitting lightbm\n",
            "Fitting MLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSAZ2LUPX_h",
        "colab_type": "code",
        "outputId": "4fdeadb3-a844-4b47-8151-fe8d17f18b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "table_cv = []\n",
        "for DApp_type in DApps_model_score:\n",
        "  cv_aucs = [cv_score for cv_score in DApps_model_score[DApp_type].values()]\n",
        "  cv_aucs.append(DApp_type)\n",
        "  table_cv.append(cv_aucs)\n",
        "\n",
        "table_cv\n",
        "table_cv = pd.DataFrame(table_cv)\n",
        "table_cv.columns = ['logit_cv','lightbm_cv','mlp_cv','category']\n",
        "table_cv.set_index('category',inplace=True)\n",
        "table_cv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit_cv</th>\n",
              "      <th>lightbm_cv</th>\n",
              "      <th>mlp_cv</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.935441</td>\n",
              "      <td>0.928132</td>\n",
              "      <td>0.932729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.964137</td>\n",
              "      <td>0.952763</td>\n",
              "      <td>0.954837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.940485</td>\n",
              "      <td>0.929450</td>\n",
              "      <td>0.922458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.929714</td>\n",
              "      <td>0.914253</td>\n",
              "      <td>0.893895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.841859</td>\n",
              "      <td>0.824604</td>\n",
              "      <td>0.722192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.962059</td>\n",
              "      <td>0.938144</td>\n",
              "      <td>0.894833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.792579</td>\n",
              "      <td>0.799204</td>\n",
              "      <td>0.665792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.835865</td>\n",
              "      <td>0.824941</td>\n",
              "      <td>0.634988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.879219</td>\n",
              "      <td>0.801234</td>\n",
              "      <td>0.688963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.816943</td>\n",
              "      <td>0.719593</td>\n",
              "      <td>0.633485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.803798</td>\n",
              "      <td>0.795385</td>\n",
              "      <td>0.580804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              logit_cv  lightbm_cv    mlp_cv\n",
              "category                                    \n",
              "games         0.935441    0.928132  0.932729\n",
              "exchanges     0.964137    0.952763  0.954837\n",
              "finance       0.940485    0.929450  0.922458\n",
              "gambling      0.929714    0.914253  0.893895\n",
              "others        0.841859    0.824604  0.722192\n",
              "high-risk     0.962059    0.938144  0.894833\n",
              "marketplaces  0.792579    0.799204  0.665792\n",
              "social        0.835865    0.824941  0.634988\n",
              "development   0.879219    0.801234  0.688963\n",
              "media         0.816943    0.719593  0.633485\n",
              "property      0.803798    0.795385  0.580804"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnNyZnBWkxZS",
        "colab_type": "code",
        "outputId": "129fcf7c-345d-4c42-de36-7ffa86d3cd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "table_cv.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "logit_cv      0.892546\n",
              "lightbm_cv    0.870717\n",
              "mlp_cv        0.762716\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo0nYEO6dZmC",
        "colab_type": "text"
      },
      "source": [
        "Optional: save cv scores?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyY1TRZW9Ppl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "types = 'punctuations_preserved'\n",
        "cv_result.loc[(cv_result['models']=='logit') & (cv_result['input_types']==types),'AUC'] = table_cv.loc[:,'logit_cv'].values\n",
        "cv_result.loc[(cv_result['models']=='lightbm') & (cv_result['input_types']==types),'AUC'] = table_cv.loc[:,'lightbm_cv'].values\n",
        "cv_result.loc[(cv_result['models']=='mlp') & (cv_result['input_types']==types),'AUC'] = table_cv.loc[:,'mlp_cv'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WopZUf4kWuJ",
        "colab_type": "text"
      },
      "source": [
        "run on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K83P8DTUIZSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main function\n",
        "\n",
        "test_aucs = []\n",
        "for DApp_type in data['category'].value_counts().index:\n",
        "  y_train = np.array(Y_train[DApp_type])\n",
        "  y_test = np.array(Y_test[DApp_type])\n",
        "\n",
        "  #X_train_set = np.array(X_non_NLP_features(X_train))\n",
        "  #X_train_set = vectorizer_comments.fit_transform(X_train['comments'])\n",
        "  #X_train_set = vectorizer_codes.fit_transform(X_train['uncommented'])\n",
        "  X_train_set = vectorizer_combined.fit_transform(X_train['source_code'])\n",
        "\n",
        "  #X_test_xNLP = np.array(X_non_NLP_features(X_test))\n",
        "  #X_test_set = vectorizer_comments.transform(X_test['comments'])\n",
        "  #X_test_set = vectorizer_codes.transform(X_test['uncommented'])\n",
        "  X_test_set = vectorizer_combined.transform(X_test['source_code'])\n",
        "\n",
        "  scaler = MaxAbsScaler()\n",
        "  X_train_set = scaler.fit_transform(X_train_set)\n",
        "  X_test_set = scaler.transform(X_test_set)\n",
        "\n",
        "  logit = logit_model(X_train_set,y_train,DApps_model_params[DApp_type]['logit_params'])\n",
        "  lightbm = lightbm_model(X_train_set,y_train,DApps_model_params[DApp_type]['lgb_params'])\n",
        "  mlp = mlp_model(X_train_set,y_train,DApps_model_params[DApp_type]['mlp_params'])\n",
        "\n",
        "  test_aucs.append([DApp_type,roc_auc_score(y_test,logit.predict(X_test_set)),roc_auc_score(y_test,lightbm.predict(X_test_set)),roc_auc_score(y_test,[x[1] for x in mlp.predict_proba(X_test_set)])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz8HZikIS7nU",
        "colab_type": "code",
        "outputId": "5761e790-b26d-454e-dcde-bc1b167bd80e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "# output\n",
        "table_test = pd.DataFrame(test_aucs)\n",
        "table_test.columns = ['category','logit','lightbm','mlp']\n",
        "table_test.set_index('category',inplace=True)\n",
        "table_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit</th>\n",
              "      <th>lightbm</th>\n",
              "      <th>mlp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.875955</td>\n",
              "      <td>0.932629</td>\n",
              "      <td>0.959970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.963336</td>\n",
              "      <td>0.972408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.792276</td>\n",
              "      <td>0.877071</td>\n",
              "      <td>0.928504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.754802</td>\n",
              "      <td>0.944657</td>\n",
              "      <td>0.933971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.582335</td>\n",
              "      <td>0.865203</td>\n",
              "      <td>0.801863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.737162</td>\n",
              "      <td>0.926395</td>\n",
              "      <td>0.918521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.796125</td>\n",
              "      <td>0.649486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.636873</td>\n",
              "      <td>0.660310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.664717</td>\n",
              "      <td>0.738304</td>\n",
              "      <td>0.721464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.703937</td>\n",
              "      <td>0.813115</td>\n",
              "      <td>0.668116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.623073</td>\n",
              "      <td>0.799213</td>\n",
              "      <td>0.757707</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 logit   lightbm       mlp\n",
              "category                                  \n",
              "games         0.875955  0.932629  0.959970\n",
              "exchanges     0.891304  0.963336  0.972408\n",
              "finance       0.792276  0.877071  0.928504\n",
              "gambling      0.754802  0.944657  0.933971\n",
              "others        0.582335  0.865203  0.801863\n",
              "high-risk     0.737162  0.926395  0.918521\n",
              "marketplaces  0.619048  0.796125  0.649486\n",
              "social        0.500000  0.636873  0.660310\n",
              "development   0.664717  0.738304  0.721464\n",
              "media         0.703937  0.813115  0.668116\n",
              "property      0.623073  0.799213  0.757707"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKxdonOymO5-",
        "colab_type": "text"
      },
      "source": [
        "optional: save test auc?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSbpspRNmR68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "types = 'punctuations_preserved'\n",
        "result.loc[(result['models']=='logit') & (result['input_types']==types),'AUC'] = table_test.loc[:,'logit'].values\n",
        "result.loc[(result['models']=='lightbm') & (result['input_types']==types),'AUC'] = table_test.loc[:,'lightbm'].values\n",
        "result.loc[(result['models']=='mlp') & (result['input_types']==types),'AUC'] = table_test.loc[:,'mlp'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_lDC5VGmUYi",
        "colab_type": "text"
      },
      "source": [
        "A combined table of cv and test aucs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFkJGMicidr0",
        "colab_type": "code",
        "outputId": "75a7f8bd-8ec5-40a2-dd4a-1cfd751bc9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "table = table_test.join(table_cv)\n",
        "table.loc[:,('logit_cv','logit','lightbm_cv','lightbm','mlp_cv','mlp')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit_cv</th>\n",
              "      <th>logit</th>\n",
              "      <th>lightbm_cv</th>\n",
              "      <th>lightbm</th>\n",
              "      <th>mlp_cv</th>\n",
              "      <th>mlp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.903527</td>\n",
              "      <td>0.806944</td>\n",
              "      <td>0.912480</td>\n",
              "      <td>0.919544</td>\n",
              "      <td>0.886719</td>\n",
              "      <td>0.906730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.959379</td>\n",
              "      <td>0.899540</td>\n",
              "      <td>0.955496</td>\n",
              "      <td>0.937949</td>\n",
              "      <td>0.946653</td>\n",
              "      <td>0.961716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.904681</td>\n",
              "      <td>0.738059</td>\n",
              "      <td>0.908626</td>\n",
              "      <td>0.892642</td>\n",
              "      <td>0.875982</td>\n",
              "      <td>0.864202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.887796</td>\n",
              "      <td>0.738960</td>\n",
              "      <td>0.900053</td>\n",
              "      <td>0.835281</td>\n",
              "      <td>0.888690</td>\n",
              "      <td>0.880790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.845451</td>\n",
              "      <td>0.531337</td>\n",
              "      <td>0.839435</td>\n",
              "      <td>0.784331</td>\n",
              "      <td>0.818368</td>\n",
              "      <td>0.799468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.905216</td>\n",
              "      <td>0.694668</td>\n",
              "      <td>0.896943</td>\n",
              "      <td>0.884201</td>\n",
              "      <td>0.864426</td>\n",
              "      <td>0.932557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.774803</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.754351</td>\n",
              "      <td>0.759150</td>\n",
              "      <td>0.764272</td>\n",
              "      <td>0.795798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.758435</td>\n",
              "      <td>0.498047</td>\n",
              "      <td>0.722853</td>\n",
              "      <td>0.639597</td>\n",
              "      <td>0.744929</td>\n",
              "      <td>0.752981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.820489</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.813542</td>\n",
              "      <td>0.779186</td>\n",
              "      <td>0.754994</td>\n",
              "      <td>0.800032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.816791</td>\n",
              "      <td>0.528439</td>\n",
              "      <td>0.768849</td>\n",
              "      <td>0.718986</td>\n",
              "      <td>0.748617</td>\n",
              "      <td>0.734321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.819428</td>\n",
              "      <td>0.539740</td>\n",
              "      <td>0.787029</td>\n",
              "      <td>0.645793</td>\n",
              "      <td>0.791999</td>\n",
              "      <td>0.808847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              logit_cv     logit  lightbm_cv   lightbm    mlp_cv       mlp\n",
              "category                                                                  \n",
              "games         0.903527  0.806944    0.912480  0.919544  0.886719  0.906730\n",
              "exchanges     0.959379  0.899540    0.955496  0.937949  0.946653  0.961716\n",
              "finance       0.904681  0.738059    0.908626  0.892642  0.875982  0.864202\n",
              "gambling      0.887796  0.738960    0.900053  0.835281  0.888690  0.880790\n",
              "others        0.845451  0.531337    0.839435  0.784331  0.818368  0.799468\n",
              "high-risk     0.905216  0.694668    0.896943  0.884201  0.864426  0.932557\n",
              "marketplaces  0.774803  0.595238    0.754351  0.759150  0.764272  0.795798\n",
              "social        0.758435  0.498047    0.722853  0.639597  0.744929  0.752981\n",
              "development   0.820489  0.583333    0.813542  0.779186  0.754994  0.800032\n",
              "media         0.816791  0.528439    0.768849  0.718986  0.748617  0.734321\n",
              "property      0.819428  0.539740    0.787029  0.645793  0.791999  0.808847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRYoh7TYsiq",
        "colab_type": "text"
      },
      "source": [
        "# Sequential Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlMQ0_DfueAO",
        "colab_type": "text"
      },
      "source": [
        "## Word-to-Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN0eP1yvPDJv",
        "colab_type": "code",
        "outputId": "703efddc-026e-4978-aa82-b988f0660a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIpWBwFLMN4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check out the first 20 comments as a sample for tokenizing\n",
        "regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "corpus = ' '.join(X_train[0:20]['comments'].values)\n",
        "new_words = regex_tokenizer.tokenize(corpus)\n",
        "\n",
        "new_words = sum([word.split('_') for word in new_words],[])\n",
        "new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words] #split cramelCase\n",
        "new_words = sum(new_words, [])\n",
        "\n",
        "fdist1 = nltk.FreqDist(new_words)\n",
        "fdist1.most_common(50)\n",
        "#len(np.unique(new_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJ6nQ6beoWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define tokenizer that's fit for comments\n",
        "def build_corpus_comments (list_of_text):\n",
        "\n",
        "  corpus = []\n",
        "\n",
        "  regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "  my_stopwords = stopwords.words(\"english\")\n",
        "  my_stopwords.append(\"\")\n",
        "\n",
        "  for i in range(0,len(list_of_text)):\n",
        "    text = list_of_text[i]\n",
        "    text = regex_tokenizer.tokenize(text)\n",
        "    text = sum([word.split('_') for word in text],[])\n",
        "    text = [re.sub('[0-9]','', word) for word in text]\n",
        "    text = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in text]\n",
        "    text = sum(text, [])\n",
        "\n",
        "    text = [w for w in text if not w in my_stopwords]\n",
        "    corpus.append(text)\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1deFVmnRavk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define tokenizer that's fit for codes\n",
        "def build_corpus_codes (codes):\n",
        "  corpus = []\n",
        "  my_stopwords = stopwords.words(\"english\")\n",
        "  my_stopwords.append(\"\")\n",
        "  \n",
        "  for i in range(0,len(codes)):\n",
        "    text = codes[i]\n",
        "    text = nltk.word_tokenize(text)\n",
        "    text = sum([word.split('_') for word in text],[])\n",
        "    text = [re.sub('[0-9]','', word) for word in text]\n",
        "    text = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in text]\n",
        "    text = sum(text, [])\n",
        "    text = [w for w in text if not w in my_stopwords]\n",
        "    corpus.append(text)\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfnF2Y2uNl4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize but check if the num_words makes sense from the vocal sizes in the subsequent code blocks\n",
        "num_words=5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHyA_nw9rVVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build corpus base on the comments\n",
        "comments_train_corpus = build_corpus_comments(X_train['comments'].values)\n",
        "comments_test_corpus = build_corpus_comments(X_test['comments'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xCJcGlSJqlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build corpus base on the codes\n",
        "codes_train_corpus = build_corpus_codes(X_train['uncommented'].values)\n",
        "codes_test_corpus = build_corpus_codes(X_test['uncommented'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCmS7BXO6RG",
        "colab_type": "code",
        "outputId": "125b329f-7342-4fc2-b961-e46a9f9abe07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tokenize_to_seq comments\n",
        "tokenizer_obj=Tokenizer(num_words=num_words, lower=True)\n",
        "tokenizer_obj.fit_on_texts(comments_train_corpus)\n",
        "comments_train_seq=tokenizer_obj.texts_to_sequences(comments_train_corpus)\n",
        "comments_test_seq=tokenizer_obj.texts_to_sequences(comments_test_corpus)\n",
        "len(tokenizer_obj.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11871"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7RODnzZKOx2",
        "colab_type": "code",
        "outputId": "52f4271d-d326-4485-e53f-8c42b36e66d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tokenize_to_seq codes\n",
        "tokenizer_obj=Tokenizer(num_words=num_words, lower=True)\n",
        "tokenizer_obj.fit_on_texts(codes_train_corpus)\n",
        "codes_train_seq=tokenizer_obj.texts_to_sequences(codes_train_corpus)\n",
        "codes_test_seq=tokenizer_obj.texts_to_sequences(codes_test_corpus)\n",
        "len(tokenizer_obj.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgyojuMcZbph",
        "colab_type": "code",
        "outputId": "450c58ba-fa7e-45cf-e678-acc93ba23f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# set maxlen to be padded based on text length after tokenization\n",
        "comment_len = [len(comments) for comments in comments_train_seq]\n",
        "code_len = [len(codes) for codes in codes_train_seq]\n",
        "\n",
        "maxlen = 5000\n",
        "(np.mean(comment_len), np.mean(code_len)),(1*np.std(comment_len),1*np.std(code_len)),(max(comment_len),max(code_len))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((931.4538606403013, 3181.263025737602),\n",
              " (1215.0385584799635, 3205.5700603279906),\n",
              " (8452, 38147))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6jrp96CTKab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad\n",
        "comments_train_seq=pad_sequences(comments_train_seq,maxlen=maxlen)\n",
        "comments_test_seq=pad_sequences(comments_test_seq,maxlen=maxlen)\n",
        "\n",
        "codes_train_seq=pad_sequences(codes_train_seq,maxlen=maxlen)\n",
        "codes_test_seq=pad_sequences(codes_test_seq,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB9pphwKbIlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build corpus base on the combined\n",
        "combined_train_corpus = build_corpus_codes(X_train['source_code'].values)\n",
        "combined_test_corpus = build_corpus_codes(X_test['source_code'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo-IxvMubMPm",
        "colab_type": "code",
        "outputId": "35e478d4-0a7c-4c77-d7a2-5c22bd24568b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num_words=10000\n",
        "\n",
        "tokenizer_obj=Tokenizer(num_words=num_words, lower=True)\n",
        "tokenizer_obj.fit_on_texts(combined_train_corpus)\n",
        "combined_train_seq=tokenizer_obj.texts_to_sequences(combined_train_corpus)\n",
        "combined_test_seq=tokenizer_obj.texts_to_sequences(combined_test_corpus)\n",
        "len(tokenizer_obj.word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duedEYKibMNB",
        "colab_type": "code",
        "outputId": "e47263e9-4c5d-4876-b583-f2b63247b78f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "combined_len = [len(combined) for combined in combined_train_corpus]\n",
        "np.mean(combined_len),max(combined_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4625.24670433145, 44904)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbzA7AUjbMKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 10000\n",
        "combined_train_seq=pad_sequences(combined_train_seq,maxlen=maxlen)\n",
        "combined_test_seq=pad_sequences(combined_test_seq,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgR7R9ywvdW6",
        "colab_type": "text"
      },
      "source": [
        "### Alternative Pre-trained Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9GyO163ZnR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBNYwkn9se7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download the pre-trained weights\n",
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zodYvSBitFYm",
        "colab_type": "code",
        "outputId": "55510366-3f4e-4501-d38d-0ae6cfb43033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# store it in the W2V format\n",
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "googlenews_w2v = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZexf6dvv08t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the W2V weight matrix\n",
        "googlenews_w2v_matrix = np.zeros((len(word_index) + 1, 300))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Oi6Czv5zF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the vocabulary\n",
        "key = list(googlenews_w2v.vocab.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-5TOO3wKOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fill in the W2V weight matrix\n",
        "for word,i in word_index.items():\n",
        "  if word in key:\n",
        "    googlenews_w2v_matrix[i] = googlenews_w2v.get_vector(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2mb2K18XMgB",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3TIUkbKisMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling1D, MaxPooling2D, Flatten, Input, Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWq83AC2YsLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decide X to be comments or codes or combined\n",
        "X_train_seq = comments_train_seq\n",
        "X_test_seq = comments_test_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KRM6nw0pnLA",
        "colab_type": "text"
      },
      "source": [
        "define models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQAQsbCEXuQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_GRU (optimizer='adam', GRU_size=128, dropout=0.2):\n",
        "  initializer=keras.initializers.he_normal()\n",
        "\n",
        "  input_NLP = Input(shape=(maxlen,))\n",
        "  embedding_layer = Embedding(input_dim=num_words,output_dim=100,input_length=maxlen,trainable=True)\n",
        "  RNN = embedding_layer(input_NLP)\n",
        "  RNN = GRU(GRU_size,activation='tanh',kernel_initializer=initializer,return_sequences=False)(RNN)\n",
        "  #RNN = Bidirectional(GRU(GRU_size,activation='tanh'),merge_mode=\"concat\")(RNN) #(Bidirectional(GRU(32,return_sequences=True)))\n",
        "  #RNN = GRU(GRU_size,activation='tanh',kernel_initializer=initializer,return_sequences=False)(RNN)\n",
        "  RNN = Dropout(dropout)(RNN)\n",
        "  RNN = Dense(64,activation='tanh',kernel_initializer=initializer)(RNN)\n",
        "  RNN = Dropout(dropout)(RNN)\n",
        "  predictions = Dense(11,activation='softmax',kernel_initializer=initializer)(RNN)\n",
        "  RNN = Model(inputs=input_NLP, outputs=predictions)\n",
        "  RNN.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "  return RNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ptgDYhbr-5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_CNN (optimizer='adam', filter_size=64, kernel_size=3, dropout=0.2):\n",
        "  initializer=keras.initializers.he_normal()\n",
        "\n",
        "  input_NLP = Input(shape=(maxlen,))\n",
        "  embedding_layer = Embedding(input_dim=num_words,output_dim=100,input_length=maxlen,trainable=True)\n",
        "  CNN = embedding_layer(input_NLP)\n",
        "  CNN = Dropout(dropout)(CNN)\n",
        "  CNN = Conv1D(filters=filter_size,kernel_size=kernel_size,padding='valid',activation='relu')(CNN)\n",
        "  CNN = GlobalMaxPooling1D()(CNN)\n",
        "  CNN = Dropout(dropout)(CNN)\n",
        "  CNN = Dense(32,activation='relu',kernel_initializer=initializer)(CNN)\n",
        "  CNN = Dropout(dropout)(CNN)\n",
        "  predictions = Dense(11,activation='softmax',kernel_initializer=initializer)(CNN)\n",
        "  CNN = Model(inputs=input_NLP, outputs=predictions)\n",
        "  CNN.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "  return CNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJRXlBmq8FV",
        "colab_type": "text"
      },
      "source": [
        "Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB92fzDDv91B",
        "colab_type": "code",
        "outputId": "f9596517-a57c-4564-86bd-79cd451be306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# validate for comments\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "i = 0\n",
        "val_auc_comments = {'GRU':[[],[],[]],'CNN':[[],[],[]]} #initiate a matrix to save cv auc scores\n",
        "\n",
        "for train_index, val_index in skf.split(combined_train_seq, np.array(Y_train).argmax(1)):\n",
        "  CV_X_train = combined_train_seq[train_index]\n",
        "  CV_Y_train = np.array(Y_train)[train_index]\n",
        "  CV_X_val = combined_train_seq[val_index]\n",
        "  CV_Y_val = np.array(Y_train)[val_index]\n",
        "  Y_val = pd.DataFrame(CV_Y_val,columns=Y_train.columns)\n",
        "  \n",
        "  cb=EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=2, restore_best_weights=True)\n",
        "\n",
        "  #train GRU\n",
        "  GRU_model = create_GRU()\n",
        "  print(\"\\n\",\"Training for GRU, fold#=\", i+1,\"\\n\")\n",
        "  GRU_model.fit(CV_X_train, CV_Y_train,batch_size=100, epochs=30, verbose=1,validation_data=(CV_X_val,CV_Y_val), callbacks=[cb],shuffle=False)\n",
        "  GRU_pred = GRU_model.predict(CV_X_val)\n",
        "  GRU_pred = pd.DataFrame(GRU_pred,columns=Y_train.columns)\n",
        "  for DApp in Y_train.columns:\n",
        "    val_auc_comments['GRU'][i].append([DApp,roc_auc_score(Y_val[DApp],GRU_pred[DApp])])  \n",
        "\n",
        "  #train CNN\n",
        "  CNN = create_CNN()\n",
        "  print(\"\\n\",\"Training for CNN, fold#=\", i+1,\"\\n\")\n",
        "  CNN.fit(CV_X_train, CV_Y_train,batch_size=100, epochs=30, verbose=1,validation_data=(CV_X_val,CV_Y_val), callbacks=[cb],shuffle=False)\n",
        "  CNN_pred = CNN.predict(CV_X_val)\n",
        "  CNN_pred = pd.DataFrame(CNN_pred,columns=Y_train.columns)\n",
        "  for DApp in Y_train.columns:\n",
        "    val_auc_comments['CNN'][i].append([DApp,roc_auc_score(Y_val[DApp],CNN_pred[DApp])])\n",
        "  \n",
        "  #count add\n",
        "  i=i+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Training for GRU, fold#= 1 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 501s 471ms/step - loss: 2.3110 - val_loss: 2.1375\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 501s 471ms/step - loss: 2.0875 - val_loss: 1.9874\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 494s 465ms/step - loss: 1.9237 - val_loss: 1.7840\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 496s 467ms/step - loss: 1.7542 - val_loss: 1.7351\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 498s 469ms/step - loss: 1.6263 - val_loss: 1.6740\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 502s 473ms/step - loss: 1.4749 - val_loss: 1.6600\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 504s 475ms/step - loss: 1.3460 - val_loss: 1.7726\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 504s 475ms/step - loss: 1.3654 - val_loss: 1.7060\n",
            "\n",
            " Training for CNN, fold#= 1 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.2294 - val_loss: 2.0394\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.0160 - val_loss: 1.8813\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.8944 - val_loss: 1.7802\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.7973 - val_loss: 1.6958\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.7054 - val_loss: 1.6118\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.6164 - val_loss: 1.5338\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.5101 - val_loss: 1.4592\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.4202 - val_loss: 1.3883\n",
            "Epoch 9/30\n",
            "1062/1062 [==============================] - 53s 50ms/step - loss: 1.3144 - val_loss: 1.3229\n",
            "Epoch 10/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.2540 - val_loss: 1.2689\n",
            "Epoch 11/30\n",
            "1062/1062 [==============================] - 53s 50ms/step - loss: 1.1690 - val_loss: 1.2247\n",
            "Epoch 12/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.1092 - val_loss: 1.1845\n",
            "Epoch 13/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.0612 - val_loss: 1.1503\n",
            "Epoch 14/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.0065 - val_loss: 1.1218\n",
            "Epoch 15/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.9151 - val_loss: 1.0992\n",
            "Epoch 16/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8978 - val_loss: 1.0768\n",
            "Epoch 17/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8261 - val_loss: 1.0587\n",
            "Epoch 18/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8062 - val_loss: 1.0443\n",
            "Epoch 19/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.7490 - val_loss: 1.0303\n",
            "Epoch 20/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.7261 - val_loss: 1.0150\n",
            "Epoch 21/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6857 - val_loss: 1.0047\n",
            "Epoch 22/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6232 - val_loss: 0.9978\n",
            "Epoch 23/30\n",
            "1062/1062 [==============================] - 53s 50ms/step - loss: 0.6027 - val_loss: 0.9949\n",
            "Epoch 24/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5602 - val_loss: 0.9932\n",
            "Epoch 25/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5485 - val_loss: 0.9916\n",
            "Epoch 26/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5055 - val_loss: 0.9909\n",
            "Epoch 27/30\n",
            "1062/1062 [==============================] - 53s 50ms/step - loss: 0.4996 - val_loss: 0.9893\n",
            "Epoch 28/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.4570 - val_loss: 0.9944\n",
            "Epoch 29/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.4557 - val_loss: 0.9945\n",
            "\n",
            " Training for GRU, fold#= 2 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 506s 477ms/step - loss: 2.2662 - val_loss: 2.0933\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 506s 476ms/step - loss: 2.0844 - val_loss: 2.0175\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 505s 476ms/step - loss: 1.9727 - val_loss: 1.8334\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 508s 478ms/step - loss: 1.8061 - val_loss: 1.7573\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 509s 479ms/step - loss: 1.6977 - val_loss: 1.7420\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 508s 478ms/step - loss: 1.6556 - val_loss: 1.6958\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 509s 479ms/step - loss: 1.4822 - val_loss: 1.6477\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 512s 482ms/step - loss: 1.2868 - val_loss: 1.6107\n",
            "Epoch 9/30\n",
            "1062/1062 [==============================] - 514s 484ms/step - loss: 1.1349 - val_loss: 1.6360\n",
            "Epoch 10/30\n",
            "1062/1062 [==============================] - 513s 483ms/step - loss: 1.0142 - val_loss: 1.7231\n",
            "\n",
            " Training for CNN, fold#= 2 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            " 700/1062 [==================>...........] - ETA: 16s - loss: 2.4114"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sIsZjqYift3",
        "colab_type": "code",
        "outputId": "879c9f0c-d1bb-4ca8-eaba-2aec1486d554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "  # validate again with AUC scoring\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "i = 0\n",
        "val_auc_codes = {'GRU':[[],[],[]],'CNN':[[],[],[]]} #initiate a matrix to save cv auc scores\n",
        "\n",
        "for train_index, val_index in skf.split(combined_train_seq, np.array(Y_train).argmax(1)):\n",
        "  CV_X_train = combined_train_seq[train_index]\n",
        "  CV_Y_train = np.array(Y_train)[train_index]\n",
        "  CV_X_val = combined_train_seq[val_index]\n",
        "  CV_Y_val = np.array(Y_train)[val_index]\n",
        "  Y_val = pd.DataFrame(CV_Y_val,columns=Y_train.columns)\n",
        "  \n",
        "  cb=EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=2, restore_best_weights=True)\n",
        "\n",
        "  #train GRU\n",
        "  GRU_model = create_GRU()\n",
        "  print(\"\\n\",\"Training for GRU, fold#=\", i+1,\"\\n\")\n",
        "  GRU_model.fit(CV_X_train, CV_Y_train,batch_size=100, epochs=30, verbose=1,validation_data=(CV_X_val,CV_Y_val), callbacks=[cb],shuffle=False)\n",
        "  GRU_pred = GRU_model.predict(CV_X_val)\n",
        "  GRU_pred = pd.DataFrame(GRU_pred,columns=Y_train.columns)\n",
        "  for DApp in Y_train.columns:\n",
        "    val_auc_codes['GRU'][i].append([DApp,roc_auc_score(Y_val[DApp],GRU_pred[DApp])])\n",
        "\n",
        "  #train CNN\n",
        "  CNN = create_CNN()\n",
        "  print(\"\\n\",\"Training for CNN, fold#=\", i+1,\"\\n\")\n",
        "  CNN.fit(CV_X_train, CV_Y_train,batch_size=100, epochs=30, verbose=1,validation_data=(CV_X_val,CV_Y_val), callbacks=[cb],shuffle=False)\n",
        "  CNN_pred = CNN.predict(CV_X_val)\n",
        "  CNN_pred = pd.DataFrame(CNN_pred,columns=Y_train.columns)\n",
        "  for DApp in Y_train.columns:\n",
        "    val_auc_codes['CNN'][i].append([DApp,roc_auc_score(Y_val[DApp],CNN_pred[DApp])])\n",
        "    \n",
        "  #count add\n",
        "  i=i+1  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Training for GRU, fold#= 1 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 519s 489ms/step - loss: 2.2930 - val_loss: 2.1269\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 508s 478ms/step - loss: 2.0869 - val_loss: 2.0319\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 488s 459ms/step - loss: 1.9904 - val_loss: 1.9232\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 489s 461ms/step - loss: 1.8076 - val_loss: 1.8565\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 489s 460ms/step - loss: 1.7017 - val_loss: 1.7800\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 486s 458ms/step - loss: 1.5668 - val_loss: 1.8029\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 494s 465ms/step - loss: 1.4350 - val_loss: 1.7069\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 502s 473ms/step - loss: 1.3457 - val_loss: 1.7406\n",
            "Epoch 9/30\n",
            "1062/1062 [==============================] - 504s 474ms/step - loss: 1.1602 - val_loss: 1.7773\n",
            "\n",
            " Training for CNN, fold#= 1 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.3873 - val_loss: 2.2477\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.1644 - val_loss: 2.0435\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.9710 - val_loss: 1.8765\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 1.8446 - val_loss: 1.7867\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 1.7639 - val_loss: 1.7276\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 1.6758 - val_loss: 1.6652\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 1.5814 - val_loss: 1.5876\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 1.5007 - val_loss: 1.5172\n",
            "Epoch 9/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.4399 - val_loss: 1.4490\n",
            "Epoch 10/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.3539 - val_loss: 1.3920\n",
            "Epoch 11/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.2786 - val_loss: 1.3371\n",
            "Epoch 12/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.1619 - val_loss: 1.2926\n",
            "Epoch 13/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.1132 - val_loss: 1.2567\n",
            "Epoch 14/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.0489 - val_loss: 1.2219\n",
            "Epoch 15/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.9890 - val_loss: 1.1972\n",
            "Epoch 16/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.9389 - val_loss: 1.1733\n",
            "Epoch 17/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.9095 - val_loss: 1.1588\n",
            "Epoch 18/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8555 - val_loss: 1.1424\n",
            "Epoch 19/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.7925 - val_loss: 1.1250\n",
            "Epoch 20/30\n",
            "1062/1062 [==============================] - 53s 50ms/step - loss: 0.7624 - val_loss: 1.1209\n",
            "Epoch 21/30\n",
            "1062/1062 [==============================] - 56s 53ms/step - loss: 0.7239 - val_loss: 1.1131\n",
            "Epoch 22/30\n",
            "1062/1062 [==============================] - 55s 52ms/step - loss: 0.7003 - val_loss: 1.0981\n",
            "Epoch 23/30\n",
            "1062/1062 [==============================] - 55s 52ms/step - loss: 0.6485 - val_loss: 1.1016\n",
            "Epoch 24/30\n",
            "1062/1062 [==============================] - 53s 50ms/step - loss: 0.5916 - val_loss: 1.0909\n",
            "Epoch 25/30\n",
            "1062/1062 [==============================] - 53s 50ms/step - loss: 0.5839 - val_loss: 1.0977\n",
            "Epoch 26/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5663 - val_loss: 1.1025\n",
            "\n",
            " Training for GRU, fold#= 2 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 492s 463ms/step - loss: 2.2597 - val_loss: 2.1012\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 487s 459ms/step - loss: 2.0557 - val_loss: 1.9763\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 483s 455ms/step - loss: 1.8824 - val_loss: 1.8468\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 500s 471ms/step - loss: 1.8043 - val_loss: 1.7868\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 492s 464ms/step - loss: 1.6718 - val_loss: 1.7637\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 488s 460ms/step - loss: 1.5720 - val_loss: 1.7756\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 481s 453ms/step - loss: 1.4501 - val_loss: 1.7942\n",
            "\n",
            " Training for CNN, fold#= 2 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.3489 - val_loss: 2.1948\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.1353 - val_loss: 1.9979\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.9905 - val_loss: 1.8538\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.8627 - val_loss: 1.7570\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.7275 - val_loss: 1.6772\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.6712 - val_loss: 1.6096\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.5815 - val_loss: 1.5490\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.4752 - val_loss: 1.4853\n",
            "Epoch 9/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.3954 - val_loss: 1.4275\n",
            "Epoch 10/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.3224 - val_loss: 1.3753\n",
            "Epoch 11/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.2267 - val_loss: 1.3299\n",
            "Epoch 12/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.1615 - val_loss: 1.2877\n",
            "Epoch 13/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.1153 - val_loss: 1.2563\n",
            "Epoch 14/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.0566 - val_loss: 1.2267\n",
            "Epoch 15/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.9827 - val_loss: 1.2068\n",
            "Epoch 16/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 0.9378 - val_loss: 1.1807\n",
            "Epoch 17/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 0.8683 - val_loss: 1.1627\n",
            "Epoch 18/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8235 - val_loss: 1.1506\n",
            "Epoch 19/30\n",
            "1062/1062 [==============================] - 51s 48ms/step - loss: 0.7576 - val_loss: 1.1413\n",
            "Epoch 20/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.7527 - val_loss: 1.1326\n",
            "Epoch 21/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.7098 - val_loss: 1.1237\n",
            "Epoch 22/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6716 - val_loss: 1.1220\n",
            "Epoch 23/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6271 - val_loss: 1.1148\n",
            "Epoch 24/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6186 - val_loss: 1.1071\n",
            "Epoch 25/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6048 - val_loss: 1.1019\n",
            "Epoch 26/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5668 - val_loss: 1.1089\n",
            "Epoch 27/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5123 - val_loss: 1.1175\n",
            "\n",
            " Training for GRU, fold#= 3 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 482s 454ms/step - loss: 2.2880 - val_loss: 2.1199\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 481s 453ms/step - loss: 2.0682 - val_loss: 1.9987\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 482s 454ms/step - loss: 1.9240 - val_loss: 1.8823\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 486s 458ms/step - loss: 1.8136 - val_loss: 1.7221\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 492s 463ms/step - loss: 1.7012 - val_loss: 1.6822\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 487s 458ms/step - loss: 1.5751 - val_loss: 1.6304\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 493s 464ms/step - loss: 1.4647 - val_loss: 1.7122\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 492s 463ms/step - loss: 1.3999 - val_loss: 1.6593\n",
            "\n",
            " Training for CNN, fold#= 3 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.3574 - val_loss: 2.2546\n",
            "Epoch 2/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.2115 - val_loss: 2.0917\n",
            "Epoch 3/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 2.0697 - val_loss: 1.9335\n",
            "Epoch 4/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.9428 - val_loss: 1.8033\n",
            "Epoch 5/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.8448 - val_loss: 1.6899\n",
            "Epoch 6/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.7092 - val_loss: 1.5934\n",
            "Epoch 7/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.6414 - val_loss: 1.5072\n",
            "Epoch 8/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.5651 - val_loss: 1.4290\n",
            "Epoch 9/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.4342 - val_loss: 1.3513\n",
            "Epoch 10/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.3760 - val_loss: 1.2822\n",
            "Epoch 11/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.3014 - val_loss: 1.2252\n",
            "Epoch 12/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.2191 - val_loss: 1.1789\n",
            "Epoch 13/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.1527 - val_loss: 1.1354\n",
            "Epoch 14/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.0772 - val_loss: 1.1057\n",
            "Epoch 15/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 1.0233 - val_loss: 1.0753\n",
            "Epoch 16/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.9627 - val_loss: 1.0538\n",
            "Epoch 17/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8946 - val_loss: 1.0357\n",
            "Epoch 18/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8450 - val_loss: 1.0212\n",
            "Epoch 19/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.8092 - val_loss: 1.0101\n",
            "Epoch 20/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.7886 - val_loss: 0.9984\n",
            "Epoch 21/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.7071 - val_loss: 0.9915\n",
            "Epoch 22/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6591 - val_loss: 0.9830\n",
            "Epoch 23/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6301 - val_loss: 0.9796\n",
            "Epoch 24/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.6070 - val_loss: 0.9771\n",
            "Epoch 25/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5684 - val_loss: 0.9783\n",
            "Epoch 26/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5512 - val_loss: 0.9729\n",
            "Epoch 27/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5169 - val_loss: 0.9712\n",
            "Epoch 28/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.5090 - val_loss: 0.9702\n",
            "Epoch 29/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.4625 - val_loss: 0.9651\n",
            "Epoch 30/30\n",
            "1062/1062 [==============================] - 52s 49ms/step - loss: 0.4472 - val_loss: 0.9688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1FcJNNyIREU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open('val_auc_comments.pickle', 'wb') as handle:\n",
        "#  pickle.dump(val_auc_comments, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('val_auc_codes.pickle', 'wb') as handle:\n",
        "  pickle.dump(val_auc_codes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "485Rd0efdN68",
        "colab_type": "text"
      },
      "source": [
        "Optional: test cv results and save cv results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T_3IHj_jF3M",
        "colab_type": "text"
      },
      "source": [
        "Previous best cv aucs across comments and codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDlg_xUgjDvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_comments = cv_result.loc[(cv_result['models']=='GRU') & (cv_result['input_types']=='punctuations_preserved'),'AUC']\n",
        "best_codes = cv_result.loc[(cv_result['models']=='GRU') & (cv_result['input_types']=='punctuations_preserved'),'AUC']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYtXxTs9jad8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best = np.array([best_comments.values,best_codes.values]).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JACvV5b1jifj",
        "colab_type": "code",
        "outputId": "b12fc3ed-5edb-4fd5-c0af-e227e54a70b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "best"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83927698, 0.93344563, 0.79822415, 0.83099787, 0.71119872,\n",
              "       0.72077033, 0.70858381, 0.68583786, 0.77197907, 0.75099582,\n",
              "       0.76013409, 0.83927698, 0.93344563, 0.79822415, 0.83099787,\n",
              "       0.71119872, 0.72077033, 0.70858381, 0.68583786, 0.77197907,\n",
              "       0.75099582, 0.76013409])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQesipHtjqaf",
        "colab_type": "text"
      },
      "source": [
        "Current aucs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9726f8fypdxV",
        "colab_type": "code",
        "outputId": "a497e060-994e-4170-c070-0d1197978a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# output the average AUC score\n",
        "AUC = val_auc_codes['GRU']\n",
        "cv = pd.concat([pd.DataFrame(AUC[0],columns=['categories','AUC']),pd.DataFrame(AUC[1],columns=['categories','AUC']),pd.DataFrame(AUC[2],columns=['categories','AUC'])]).groupby('categories').mean()\n",
        "cv = cv.loc[data['category'].value_counts().index,:]\n",
        "cv['AUC'].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.77002637, 0.89891768, 0.75014791, 0.74160776, 0.69213138,\n",
              "       0.71951467, 0.5924536 , 0.68179321, 0.69730159, 0.63183452,\n",
              "       0.6529898 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxA9TPR5j0vE",
        "colab_type": "code",
        "outputId": "efb83875-a6b4-44ce-bf0e-dfc8f24536f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "AUC = val_auc_codes['CNN']\n",
        "cv1 = pd.concat([pd.DataFrame(AUC[0],columns=['categories','AUC']),pd.DataFrame(AUC[1],columns=['categories','AUC']),pd.DataFrame(AUC[2],columns=['categories','AUC'])]).groupby('categories').mean()\n",
        "cv1 = cv1.loc[data['category'].value_counts().index,:]\n",
        "cv1['AUC'].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94148532, 0.97264802, 0.93970525, 0.94347193, 0.86655276,\n",
              "       0.91998702, 0.82070857, 0.81734436, 0.88478902, 0.85260612,\n",
              "       0.87936148])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTgcYRPdhJ_",
        "colab_type": "code",
        "outputId": "93f7eaf8-a36c-407e-fc53-73b5bafb726d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv['AUC'].values.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7737676654355803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbRgP2YDn2uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# update validation results\n",
        "cv_result.loc[(cv_result['models']=='GRU') & (cv_result['input_types']=='punctuations_removed'),('AUC')] = cv['AUC'].values\n",
        "cv_result.loc[(cv_result['models']=='CNN') & (cv_result['input_types']=='punctuations_removed'),('AUC')] = cv1['AUC'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv5_8h4hvLj-",
        "colab_type": "text"
      },
      "source": [
        "## train the model and run on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GLrVf4XabMj",
        "colab_type": "code",
        "outputId": "2304652e-f989-4a38-97cf-10a215ecf596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "cb=EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=2, restore_best_weights=True)\n",
        "GRU_model = create_GRU()\n",
        "GRU_model.fit(combined_train_seq, Y_train, batch_size=100, epochs=30, verbose=1,validation_split=0.25, callbacks=[cb],shuffle=False)\n",
        "GRU_pred = GRU_model.predict(combined_test_seq)\n",
        "GRU_pred = pd.DataFrame(GRU_pred,columns=Y_train.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1194 samples, validate on 399 samples\n",
            "Epoch 1/30\n",
            "1194/1194 [==============================] - 583s 488ms/step - loss: 2.2782 - val_loss: 2.1058\n",
            "Epoch 2/30\n",
            "1194/1194 [==============================] - 551s 462ms/step - loss: 2.0648 - val_loss: 2.0189\n",
            "Epoch 3/30\n",
            "1194/1194 [==============================] - 527s 442ms/step - loss: 1.9411 - val_loss: 1.8217\n",
            "Epoch 4/30\n",
            "1194/1194 [==============================] - 528s 443ms/step - loss: 1.7762 - val_loss: 1.7565\n",
            "Epoch 5/30\n",
            "1194/1194 [==============================] - 528s 442ms/step - loss: 1.6884 - val_loss: 1.6603\n",
            "Epoch 6/30\n",
            "1194/1194 [==============================] - 527s 441ms/step - loss: 1.5440 - val_loss: 1.5613\n",
            "Epoch 7/30\n",
            "1194/1194 [==============================] - 547s 458ms/step - loss: 1.3368 - val_loss: 1.5668\n",
            "Epoch 8/30\n",
            "1194/1194 [==============================] - 559s 468ms/step - loss: 1.1978 - val_loss: 1.5210\n",
            "Epoch 9/30\n",
            "1194/1194 [==============================] - 553s 463ms/step - loss: 1.0582 - val_loss: 1.6155\n",
            "Epoch 10/30\n",
            "1194/1194 [==============================] - 528s 442ms/step - loss: 0.9469 - val_loss: 1.7552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umSqZVyEl1mY",
        "colab_type": "code",
        "outputId": "cb506138-aee1-40d8-f37c-ef09776fe2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "GRU_test_auc = []\n",
        "for DApp in data['category'].value_counts().index.values:\n",
        "  GRU_test_auc.append([DApp,roc_auc_score(Y_test[DApp],GRU_pred[DApp])])  \n",
        "GRU_test_auc = pd.DataFrame(GRU_test_auc,columns=['categories','AUC'])\n",
        "GRU_test_auc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>games</td>\n",
              "      <td>0.835664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>exchanges</td>\n",
              "      <td>0.899812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>finance</td>\n",
              "      <td>0.811801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gambling</td>\n",
              "      <td>0.815226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>others</td>\n",
              "      <td>0.774717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>high-risk</td>\n",
              "      <td>0.758095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>marketplaces</td>\n",
              "      <td>0.751167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>social</td>\n",
              "      <td>0.732782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development</td>\n",
              "      <td>0.701863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>media</td>\n",
              "      <td>0.689860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>property</td>\n",
              "      <td>0.648844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      categories       AUC\n",
              "0          games  0.835664\n",
              "1      exchanges  0.899812\n",
              "2        finance  0.811801\n",
              "3       gambling  0.815226\n",
              "4         others  0.774717\n",
              "5      high-risk  0.758095\n",
              "6   marketplaces  0.751167\n",
              "7         social  0.732782\n",
              "8    development  0.701863\n",
              "9          media  0.689860\n",
              "10      property  0.648844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8APX5CpnaMie",
        "colab_type": "code",
        "outputId": "d108c250-56b3-43ad-8e4e-8b9b010a33bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "cb=EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=2, restore_best_weights=True)\n",
        "CNN = create_CNN()\n",
        "CNN.fit(combined_train_seq, Y_train, batch_size=100, epochs=30, verbose=1,validation_split=0.25, callbacks=[cb],shuffle=False)\n",
        "CNN_pred = CNN.predict(combined_test_seq)\n",
        "CNN_pred = pd.DataFrame(CNN_pred,columns=Y_train.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1194 samples, validate on 399 samples\n",
            "Epoch 1/30\n",
            "1194/1194 [==============================] - 57s 47ms/step - loss: 2.3125 - val_loss: 2.1905\n",
            "Epoch 2/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 2.1262 - val_loss: 2.0277\n",
            "Epoch 3/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 2.0024 - val_loss: 1.8799\n",
            "Epoch 4/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.9037 - val_loss: 1.7553\n",
            "Epoch 5/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.8026 - val_loss: 1.6579\n",
            "Epoch 6/30\n",
            "1194/1194 [==============================] - 57s 47ms/step - loss: 1.6956 - val_loss: 1.5762\n",
            "Epoch 7/30\n",
            "1194/1194 [==============================] - 57s 47ms/step - loss: 1.5945 - val_loss: 1.4873\n",
            "Epoch 8/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.5193 - val_loss: 1.4131\n",
            "Epoch 9/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.4106 - val_loss: 1.3486\n",
            "Epoch 10/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.3426 - val_loss: 1.2901\n",
            "Epoch 11/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.2836 - val_loss: 1.2446\n",
            "Epoch 12/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.2020 - val_loss: 1.2007\n",
            "Epoch 13/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.1224 - val_loss: 1.1639\n",
            "Epoch 14/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 1.0670 - val_loss: 1.1349\n",
            "Epoch 15/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.9929 - val_loss: 1.1114\n",
            "Epoch 16/30\n",
            "1194/1194 [==============================] - 57s 47ms/step - loss: 0.9371 - val_loss: 1.0931\n",
            "Epoch 17/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.8935 - val_loss: 1.0758\n",
            "Epoch 18/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.8619 - val_loss: 1.0611\n",
            "Epoch 19/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.8018 - val_loss: 1.0465\n",
            "Epoch 20/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.7586 - val_loss: 1.0390\n",
            "Epoch 21/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.7291 - val_loss: 1.0327\n",
            "Epoch 22/30\n",
            "1194/1194 [==============================] - 57s 48ms/step - loss: 0.6739 - val_loss: 1.0287\n",
            "Epoch 23/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.6487 - val_loss: 1.0269\n",
            "Epoch 24/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.6080 - val_loss: 1.0301\n",
            "Epoch 25/30\n",
            "1194/1194 [==============================] - 56s 47ms/step - loss: 0.5523 - val_loss: 1.0288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0PbKgFBj3gE",
        "colab_type": "code",
        "outputId": "7c3ad09b-cb31-4cda-faab-e0ad7f7c8e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "CNN_test_auc = []\n",
        "for DApp in data['category'].value_counts().index.values:\n",
        "  CNN_test_auc.append([DApp,roc_auc_score(Y_test[DApp],CNN_pred[DApp])])  \n",
        "CNN_test_auc = pd.DataFrame(CNN_test_auc,columns=['categories','AUC'])\n",
        "CNN_test_auc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>games</td>\n",
              "      <td>0.957285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>exchanges</td>\n",
              "      <td>0.973474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>finance</td>\n",
              "      <td>0.943793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gambling</td>\n",
              "      <td>0.958506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>others</td>\n",
              "      <td>0.840186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>high-risk</td>\n",
              "      <td>0.938034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>marketplaces</td>\n",
              "      <td>0.937068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>social</td>\n",
              "      <td>0.865903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>development</td>\n",
              "      <td>0.880171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>media</td>\n",
              "      <td>0.881552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>property</td>\n",
              "      <td>0.864001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      categories       AUC\n",
              "0          games  0.957285\n",
              "1      exchanges  0.973474\n",
              "2        finance  0.943793\n",
              "3       gambling  0.958506\n",
              "4         others  0.840186\n",
              "5      high-risk  0.938034\n",
              "6   marketplaces  0.937068\n",
              "7         social  0.865903\n",
              "8    development  0.880171\n",
              "9          media  0.881552\n",
              "10      property  0.864001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdsRRZrDmDQ4",
        "colab_type": "text"
      },
      "source": [
        "optional save results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uRvrz6ImGRV",
        "colab_type": "code",
        "outputId": "9bb5aec9-aa95-48f4-a55b-43ce31d12235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "GRU_test_auc['AUC'].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83566434, 0.89981187, 0.81180077, 0.81522568, 0.77471723,\n",
              "       0.758095  , 0.75116713, 0.73278166, 0.70186268, 0.68986038,\n",
              "       0.64884393])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDpe39_SmGVQ",
        "colab_type": "code",
        "outputId": "523f6bf4-e567-42fb-cc6a-c55ccedcb7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "result.loc[(result['models']=='GRU') & (result['input_types']=='codes_only'),'AUC']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88   NaN\n",
              "89   NaN\n",
              "90   NaN\n",
              "91   NaN\n",
              "92   NaN\n",
              "93   NaN\n",
              "94   NaN\n",
              "95   NaN\n",
              "96   NaN\n",
              "97   NaN\n",
              "98   NaN\n",
              "Name: AUC, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKOrO6T9mGPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.loc[(result['models']=='GRU') & (result['input_types']=='punctuations_preserved'),'AUC'] = GRU_test_auc['AUC'].values\n",
        "result.loc[(result['models']=='CNN') & (result['input_types']=='punctuations_preserved'),'AUC'] = CNN_test_auc['AUC'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o3XdVRmcWJm",
        "colab_type": "text"
      },
      "source": [
        "# Present the cv and the test table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kRft3QXGlNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "order = data['category'].value_counts().index.values.tolist()\n",
        "order = [('AUC',x) for x in order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TlZxcoKWXT3",
        "colab_type": "text"
      },
      "source": [
        "## H1: Which of codes and comments in separation provides more information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRR06bZLZ2Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H1_test = pd.read_csv(\"https://raw.githubusercontent.com/HektorLin/HU-IRTG/master/H1_test.csv\",sep=',')\n",
        "H1_val = pd.read_csv(\"https://raw.githubusercontent.com/HektorLin/HU-IRTG/master/H1_validation.csv\",sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8oQ9f_6EjQT",
        "colab_type": "code",
        "outputId": "c9d86068-61e5-4857-dc1f-af4474052596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "H1_val.set_index(keys=['input_types','models','categories']).unstack('categories').loc[:,order]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"11\" halign=\"left\">AUC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>games</th>\n",
              "      <th>exchanges</th>\n",
              "      <th>finance</th>\n",
              "      <th>gambling</th>\n",
              "      <th>others</th>\n",
              "      <th>high-risk</th>\n",
              "      <th>marketplaces</th>\n",
              "      <th>social</th>\n",
              "      <th>development</th>\n",
              "      <th>media</th>\n",
              "      <th>property</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>input_types</th>\n",
              "      <th>models</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">codes_only</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.940143</td>\n",
              "      <td>0.966873</td>\n",
              "      <td>0.932744</td>\n",
              "      <td>0.933317</td>\n",
              "      <td>0.851067</td>\n",
              "      <td>0.915680</td>\n",
              "      <td>0.842207</td>\n",
              "      <td>0.843397</td>\n",
              "      <td>0.885706</td>\n",
              "      <td>0.833062</td>\n",
              "      <td>0.847884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.633049</td>\n",
              "      <td>0.883496</td>\n",
              "      <td>0.655510</td>\n",
              "      <td>0.689534</td>\n",
              "      <td>0.631175</td>\n",
              "      <td>0.557720</td>\n",
              "      <td>0.585778</td>\n",
              "      <td>0.682109</td>\n",
              "      <td>0.674383</td>\n",
              "      <td>0.671397</td>\n",
              "      <td>0.699580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>0.919171</td>\n",
              "      <td>0.949511</td>\n",
              "      <td>0.936111</td>\n",
              "      <td>0.933595</td>\n",
              "      <td>0.779749</td>\n",
              "      <td>0.943349</td>\n",
              "      <td>0.745769</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>0.830870</td>\n",
              "      <td>0.735522</td>\n",
              "      <td>0.808944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>0.930168</td>\n",
              "      <td>0.965052</td>\n",
              "      <td>0.933269</td>\n",
              "      <td>0.919571</td>\n",
              "      <td>0.839958</td>\n",
              "      <td>0.951622</td>\n",
              "      <td>0.849292</td>\n",
              "      <td>0.810565</td>\n",
              "      <td>0.848061</td>\n",
              "      <td>0.786170</td>\n",
              "      <td>0.828374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.922556</td>\n",
              "      <td>0.961909</td>\n",
              "      <td>0.914094</td>\n",
              "      <td>0.900696</td>\n",
              "      <td>0.689237</td>\n",
              "      <td>0.906723</td>\n",
              "      <td>0.708756</td>\n",
              "      <td>0.667150</td>\n",
              "      <td>0.746100</td>\n",
              "      <td>0.708507</td>\n",
              "      <td>0.611658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">comments_only</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.929964</td>\n",
              "      <td>0.964703</td>\n",
              "      <td>0.922095</td>\n",
              "      <td>0.879412</td>\n",
              "      <td>0.849770</td>\n",
              "      <td>0.894121</td>\n",
              "      <td>0.847526</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.868302</td>\n",
              "      <td>0.825457</td>\n",
              "      <td>0.802518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.839277</td>\n",
              "      <td>0.933446</td>\n",
              "      <td>0.798224</td>\n",
              "      <td>0.830998</td>\n",
              "      <td>0.711199</td>\n",
              "      <td>0.720770</td>\n",
              "      <td>0.708584</td>\n",
              "      <td>0.685838</td>\n",
              "      <td>0.771979</td>\n",
              "      <td>0.750996</td>\n",
              "      <td>0.760134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>0.911934</td>\n",
              "      <td>0.953486</td>\n",
              "      <td>0.906044</td>\n",
              "      <td>0.887956</td>\n",
              "      <td>0.757649</td>\n",
              "      <td>0.898806</td>\n",
              "      <td>0.783574</td>\n",
              "      <td>0.754704</td>\n",
              "      <td>0.817701</td>\n",
              "      <td>0.700589</td>\n",
              "      <td>0.761726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>0.899342</td>\n",
              "      <td>0.959587</td>\n",
              "      <td>0.920889</td>\n",
              "      <td>0.895338</td>\n",
              "      <td>0.806856</td>\n",
              "      <td>0.933733</td>\n",
              "      <td>0.821315</td>\n",
              "      <td>0.759296</td>\n",
              "      <td>0.856459</td>\n",
              "      <td>0.735973</td>\n",
              "      <td>0.817684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.909535</td>\n",
              "      <td>0.942705</td>\n",
              "      <td>0.896004</td>\n",
              "      <td>0.872231</td>\n",
              "      <td>0.680320</td>\n",
              "      <td>0.865220</td>\n",
              "      <td>0.631831</td>\n",
              "      <td>0.699329</td>\n",
              "      <td>0.707555</td>\n",
              "      <td>0.666602</td>\n",
              "      <td>0.543917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            AUC            ...                    \n",
              "categories                games exchanges  ...     media  property\n",
              "input_types   models                       ...                    \n",
              "codes_only    CNN      0.940143  0.966873  ...  0.833062  0.847884\n",
              "              GRU      0.633049  0.883496  ...  0.671397  0.699580\n",
              "              lightbm  0.919171  0.949511  ...  0.735522  0.808944\n",
              "              logit    0.930168  0.965052  ...  0.786170  0.828374\n",
              "              mlp      0.922556  0.961909  ...  0.708507  0.611658\n",
              "comments_only CNN      0.929964  0.964703  ...  0.825457  0.802518\n",
              "              GRU      0.839277  0.933446  ...  0.750996  0.760134\n",
              "              lightbm  0.911934  0.953486  ...  0.700589  0.761726\n",
              "              logit    0.899342  0.959587  ...  0.735973  0.817684\n",
              "              mlp      0.909535  0.942705  ...  0.666602  0.543917\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXl9Kg4lca6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H1_test.set_index(keys=['input_types','models','categories']).unstack('categories').loc[:,order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-vOdUEUdNyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6021611d-ad1c-421c-87f4-0cb872c5d298"
      },
      "source": [
        "print('NULL: comments > codes')\n",
        "for model_type in result['models'].unique():\n",
        "  comments_only = H1_test.loc[(H1_test['input_types']=='comments_only') & (result['models']==model_type),'AUC'].values\n",
        "  codes_only = H1_test.loc[(H1_test['input_types']=='codes_only') & (result['models']==model_type),'AUC'].values\n",
        "\n",
        "  print(model_type, ' ', mannwhitneyu(comments_only,codes_only,alternative='less'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NULL: comments > codes\n",
            "logit   MannwhitneyuResult(statistic=62.0, pvalue=0.5522722327507594)\n",
            "lightbm   MannwhitneyuResult(statistic=50.0, pvalue=0.2557029609250582)\n",
            "mlp   MannwhitneyuResult(statistic=55.0, pvalue=0.3713329514598411)\n",
            "GRU   MannwhitneyuResult(statistic=77.0, pvalue=0.8678542381330094)\n",
            "CNN   MannwhitneyuResult(statistic=56.0, pvalue=0.3964063083160365)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEBjkZyFWj4Y",
        "colab_type": "text"
      },
      "source": [
        "## H2: With codes and comments combined, is preserving punctuations better than not when tokenizing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5DUp_UNY5uS",
        "colab_type": "code",
        "outputId": "13551cce-ee61-451e-a3e4-1b372d005481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "cv_result.set_index(keys=['input_types','models','categories']).unstack('categories').loc[:,order]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"11\" halign=\"left\">AUC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>games</th>\n",
              "      <th>exchanges</th>\n",
              "      <th>finance</th>\n",
              "      <th>gambling</th>\n",
              "      <th>others</th>\n",
              "      <th>high-risk</th>\n",
              "      <th>marketplaces</th>\n",
              "      <th>social</th>\n",
              "      <th>development</th>\n",
              "      <th>media</th>\n",
              "      <th>property</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>input_types</th>\n",
              "      <th>models</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">punctuations_preserved</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.941485</td>\n",
              "      <td>0.972648</td>\n",
              "      <td>0.939705</td>\n",
              "      <td>0.943472</td>\n",
              "      <td>0.866553</td>\n",
              "      <td>0.919987</td>\n",
              "      <td>0.820709</td>\n",
              "      <td>0.817344</td>\n",
              "      <td>0.884789</td>\n",
              "      <td>0.852606</td>\n",
              "      <td>0.879361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.770026</td>\n",
              "      <td>0.898918</td>\n",
              "      <td>0.750148</td>\n",
              "      <td>0.741608</td>\n",
              "      <td>0.692131</td>\n",
              "      <td>0.719515</td>\n",
              "      <td>0.592454</td>\n",
              "      <td>0.681793</td>\n",
              "      <td>0.697302</td>\n",
              "      <td>0.631835</td>\n",
              "      <td>0.652990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>0.928132</td>\n",
              "      <td>0.952763</td>\n",
              "      <td>0.929450</td>\n",
              "      <td>0.914253</td>\n",
              "      <td>0.824604</td>\n",
              "      <td>0.938144</td>\n",
              "      <td>0.799204</td>\n",
              "      <td>0.824941</td>\n",
              "      <td>0.801234</td>\n",
              "      <td>0.719593</td>\n",
              "      <td>0.795385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>0.935441</td>\n",
              "      <td>0.964137</td>\n",
              "      <td>0.940485</td>\n",
              "      <td>0.929714</td>\n",
              "      <td>0.841859</td>\n",
              "      <td>0.962059</td>\n",
              "      <td>0.792579</td>\n",
              "      <td>0.835865</td>\n",
              "      <td>0.879219</td>\n",
              "      <td>0.816943</td>\n",
              "      <td>0.803798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.932729</td>\n",
              "      <td>0.954837</td>\n",
              "      <td>0.922458</td>\n",
              "      <td>0.893895</td>\n",
              "      <td>0.722192</td>\n",
              "      <td>0.894833</td>\n",
              "      <td>0.665792</td>\n",
              "      <td>0.634988</td>\n",
              "      <td>0.688963</td>\n",
              "      <td>0.633485</td>\n",
              "      <td>0.580804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">punctuations_removed</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.952966</td>\n",
              "      <td>0.972703</td>\n",
              "      <td>0.942520</td>\n",
              "      <td>0.936643</td>\n",
              "      <td>0.882508</td>\n",
              "      <td>0.943039</td>\n",
              "      <td>0.811640</td>\n",
              "      <td>0.858374</td>\n",
              "      <td>0.893546</td>\n",
              "      <td>0.867473</td>\n",
              "      <td>0.914824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.838403</td>\n",
              "      <td>0.926179</td>\n",
              "      <td>0.822374</td>\n",
              "      <td>0.772577</td>\n",
              "      <td>0.740017</td>\n",
              "      <td>0.812039</td>\n",
              "      <td>0.671206</td>\n",
              "      <td>0.716226</td>\n",
              "      <td>0.730886</td>\n",
              "      <td>0.741040</td>\n",
              "      <td>0.785720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>0.934061</td>\n",
              "      <td>0.953345</td>\n",
              "      <td>0.923282</td>\n",
              "      <td>0.922101</td>\n",
              "      <td>0.816849</td>\n",
              "      <td>0.937514</td>\n",
              "      <td>0.789868</td>\n",
              "      <td>0.811714</td>\n",
              "      <td>0.832611</td>\n",
              "      <td>0.701666</td>\n",
              "      <td>0.771046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>0.938664</td>\n",
              "      <td>0.964511</td>\n",
              "      <td>0.941005</td>\n",
              "      <td>0.933791</td>\n",
              "      <td>0.849385</td>\n",
              "      <td>0.963210</td>\n",
              "      <td>0.797090</td>\n",
              "      <td>0.855618</td>\n",
              "      <td>0.894471</td>\n",
              "      <td>0.827055</td>\n",
              "      <td>0.798405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.934470</td>\n",
              "      <td>0.950718</td>\n",
              "      <td>0.920333</td>\n",
              "      <td>0.912473</td>\n",
              "      <td>0.700771</td>\n",
              "      <td>0.886725</td>\n",
              "      <td>0.645237</td>\n",
              "      <td>0.617972</td>\n",
              "      <td>0.670542</td>\n",
              "      <td>0.647992</td>\n",
              "      <td>0.622231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     AUC            ...                    \n",
              "categories                         games exchanges  ...     media  property\n",
              "input_types            models                       ...                    \n",
              "punctuations_preserved CNN      0.941485  0.972648  ...  0.852606  0.879361\n",
              "                       GRU      0.770026  0.898918  ...  0.631835  0.652990\n",
              "                       lightbm  0.928132  0.952763  ...  0.719593  0.795385\n",
              "                       logit    0.935441  0.964137  ...  0.816943  0.803798\n",
              "                       mlp      0.932729  0.954837  ...  0.633485  0.580804\n",
              "punctuations_removed   CNN      0.952966  0.972703  ...  0.867473  0.914824\n",
              "                       GRU      0.838403  0.926179  ...  0.741040  0.785720\n",
              "                       lightbm  0.934061  0.953345  ...  0.701666  0.771046\n",
              "                       logit    0.938664  0.964511  ...  0.827055  0.798405\n",
              "                       mlp      0.934470  0.950718  ...  0.647992  0.622231\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWQAFdtDW9IY",
        "colab_type": "code",
        "outputId": "333e1e8b-c232-4090-e674-a7700c24c99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "result.set_index(keys=['input_types','models','categories']).unstack('categories').loc[:,order]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"11\" halign=\"left\">AUC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>games</th>\n",
              "      <th>exchanges</th>\n",
              "      <th>finance</th>\n",
              "      <th>gambling</th>\n",
              "      <th>others</th>\n",
              "      <th>high-risk</th>\n",
              "      <th>marketplaces</th>\n",
              "      <th>social</th>\n",
              "      <th>development</th>\n",
              "      <th>media</th>\n",
              "      <th>property</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>input_types</th>\n",
              "      <th>models</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">punctuations_preserved</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.957285</td>\n",
              "      <td>0.973474</td>\n",
              "      <td>0.943793</td>\n",
              "      <td>0.958506</td>\n",
              "      <td>0.840186</td>\n",
              "      <td>0.938034</td>\n",
              "      <td>0.937068</td>\n",
              "      <td>0.865903</td>\n",
              "      <td>0.880171</td>\n",
              "      <td>0.881552</td>\n",
              "      <td>0.864001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.835664</td>\n",
              "      <td>0.899812</td>\n",
              "      <td>0.811801</td>\n",
              "      <td>0.815226</td>\n",
              "      <td>0.774717</td>\n",
              "      <td>0.758095</td>\n",
              "      <td>0.751167</td>\n",
              "      <td>0.732782</td>\n",
              "      <td>0.701863</td>\n",
              "      <td>0.689860</td>\n",
              "      <td>0.648844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>0.932629</td>\n",
              "      <td>0.963336</td>\n",
              "      <td>0.877071</td>\n",
              "      <td>0.944657</td>\n",
              "      <td>0.865203</td>\n",
              "      <td>0.926395</td>\n",
              "      <td>0.796125</td>\n",
              "      <td>0.636873</td>\n",
              "      <td>0.738304</td>\n",
              "      <td>0.813115</td>\n",
              "      <td>0.799213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>0.875955</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.792276</td>\n",
              "      <td>0.754802</td>\n",
              "      <td>0.582335</td>\n",
              "      <td>0.737162</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.664717</td>\n",
              "      <td>0.703937</td>\n",
              "      <td>0.623073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.959970</td>\n",
              "      <td>0.972408</td>\n",
              "      <td>0.928504</td>\n",
              "      <td>0.933971</td>\n",
              "      <td>0.801863</td>\n",
              "      <td>0.918521</td>\n",
              "      <td>0.649486</td>\n",
              "      <td>0.660310</td>\n",
              "      <td>0.721464</td>\n",
              "      <td>0.668116</td>\n",
              "      <td>0.757707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">punctuations_removed</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.932503</td>\n",
              "      <td>0.962531</td>\n",
              "      <td>0.946711</td>\n",
              "      <td>0.920229</td>\n",
              "      <td>0.858916</td>\n",
              "      <td>0.892669</td>\n",
              "      <td>0.790476</td>\n",
              "      <td>0.779914</td>\n",
              "      <td>0.886358</td>\n",
              "      <td>0.856146</td>\n",
              "      <td>0.837829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.842207</td>\n",
              "      <td>0.926662</td>\n",
              "      <td>0.827345</td>\n",
              "      <td>0.830478</td>\n",
              "      <td>0.748470</td>\n",
              "      <td>0.835141</td>\n",
              "      <td>0.698133</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.783589</td>\n",
              "      <td>0.791943</td>\n",
              "      <td>0.716843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>0.932197</td>\n",
              "      <td>0.956240</td>\n",
              "      <td>0.921821</td>\n",
              "      <td>0.945655</td>\n",
              "      <td>0.821490</td>\n",
              "      <td>0.891689</td>\n",
              "      <td>0.666340</td>\n",
              "      <td>0.699784</td>\n",
              "      <td>0.742798</td>\n",
              "      <td>0.870451</td>\n",
              "      <td>0.791908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>0.868043</td>\n",
              "      <td>0.890102</td>\n",
              "      <td>0.810349</td>\n",
              "      <td>0.784802</td>\n",
              "      <td>0.582335</td>\n",
              "      <td>0.692699</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.665692</td>\n",
              "      <td>0.675498</td>\n",
              "      <td>0.624037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>0.948003</td>\n",
              "      <td>0.960723</td>\n",
              "      <td>0.924712</td>\n",
              "      <td>0.948191</td>\n",
              "      <td>0.835063</td>\n",
              "      <td>0.851934</td>\n",
              "      <td>0.855556</td>\n",
              "      <td>0.629677</td>\n",
              "      <td>0.805068</td>\n",
              "      <td>0.754063</td>\n",
              "      <td>0.757065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     AUC            ...                    \n",
              "categories                         games exchanges  ...     media  property\n",
              "input_types            models                       ...                    \n",
              "punctuations_preserved CNN      0.957285  0.973474  ...  0.881552  0.864001\n",
              "                       GRU      0.835664  0.899812  ...  0.689860  0.648844\n",
              "                       lightbm  0.932629  0.963336  ...  0.813115  0.799213\n",
              "                       logit    0.875955  0.891304  ...  0.703937  0.623073\n",
              "                       mlp      0.959970  0.972408  ...  0.668116  0.757707\n",
              "punctuations_removed   CNN      0.932503  0.962531  ...  0.856146  0.837829\n",
              "                       GRU      0.842207  0.926662  ...  0.791943  0.716843\n",
              "                       lightbm  0.932197  0.956240  ...  0.870451  0.791908\n",
              "                       logit    0.868043  0.890102  ...  0.675498  0.624037\n",
              "                       mlp      0.948003  0.960723  ...  0.754063  0.757065\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfGZ--XPo2EC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_result.to_csv('H2_validation.csv',index=False)\n",
        "result.to_csv('H2_test.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27IFlXyDbrLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8e923a81-3435-429b-e253-6763143c6e9c"
      },
      "source": [
        "print('NULL: punctuations removed > punctuations preserved')\n",
        "for model_type in result['models'].unique():\n",
        "  preserved = result.loc[(result['input_types']=='punctuations_preserved') & (result['models']==model_type),'AUC'].values\n",
        "  removed = result.loc[(result['input_types']=='punctuations_removed') & (result['models']==model_type),'AUC'].values\n",
        "\n",
        "  print(model_type, ' ', mannwhitneyu(removed, preserved, alternative='less'))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NULL: punctuations removed > punctuations preserved\n",
            "logit   MannwhitneyuResult(statistic=59.5, pvalue=0.48689297622562533)\n",
            "lightbm   MannwhitneyuResult(statistic=59.0, pvalue=0.47382226481129724)\n",
            "mlp   MannwhitneyuResult(statistic=67.0, pvalue=0.6771180898475139)\n",
            "GRU   MannwhitneyuResult(statistic=74.0, pvalue=0.8210333150533)\n",
            "CNN   MannwhitneyuResult(statistic=40.0, pvalue=0.09454090298225809)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3f_LggVW9n8",
        "colab_type": "text"
      },
      "source": [
        "## H3: Will the average of model predictions from codes and comments outperform that from combined?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPy5ZXAOXuV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkdk8gxtXuq-",
        "colab_type": "text"
      },
      "source": [
        "## H4: The best AUC possible?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocfXDh12fchk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbwgwSNIolU3",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2CewOrwoo9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYxlk7khynIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = []\n",
        "for i in range(len(comments_train_seq)):\n",
        "   train_data.append([comments_train_seq[i], np.array(Y_train_labels)[i]])\n",
        "test_data = []\n",
        "for i in range(len(comments_test_seq)):\n",
        "   test_data.append([comments_test_seq[i], np.array(Y_test)[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMytepkozIKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=100)\n",
        "testloader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFgPrIAPofaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 5000\n",
        "EMBED_DIM = 100\n",
        "NUN_CLASS = 11\n",
        "BATCH_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGeHhbmh2BBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,embed_dim): #hyperparameters for creating a model with layers\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=False)\n",
        "    #self.cnn = nn.Conv1d(5000, 128, kernel_size=3, padding=1)\n",
        "    self.cnn = nn.Conv2d(1, 64, (3, embed_dim), padding=1)\n",
        "    self.pool1 = nn.MaxPool1d(kernel_size=100)\n",
        "    self.layer2 = nn.Linear(128, 32)\n",
        "    self.layer3 = nn.Linear(32, 11)\n",
        "\n",
        "  def conv_block(self, input, conv_layer):\n",
        "    conv_out = conv_layer(input) # conv_out.size() = (batch_size, out_channels, dim, 1)\n",
        "    print(conv_out.size())\n",
        "    activation = F.relu(conv_out.squeeze(3)) # activation.size() = (batch_size, out_channels, dim1)\n",
        "    print(activation.size())\n",
        "    max_out = F.max_pool1d(activation, activation.size()[2]).squeeze(2) # maxpool_out.size() = (batch_size, out_channels)\n",
        "    return max_out\n",
        "\n",
        "  def forward(self, input_texts): #define input to this model and the sequence\n",
        "    input_emb = self.embedding(input_texts)\n",
        "    input_emb = input_emb.unsqueeze(1)\n",
        "    print(input_emb.size()) #=[batch_size,1,pad_len,emb_dim]\n",
        "    max_out = self.conv_block(input_emb, self.cnn)\n",
        "    print(max_out.size())\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRRpXVpuv3bN",
        "colab_type": "code",
        "outputId": "0ae0beab-d2ad-4f7a-b08d-b00de675bdbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "model = ConvNet(5000,100)\n",
        "for text,labels in trainloader:\n",
        "  text = text.long()\n",
        "  model(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 5000, 100])\n",
            "torch.Size([100, 64, 5000, 3])\n",
            "torch.Size([100, 64, 5000, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ef8e80d3546a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-b2b579a7ab64>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_texts)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0minput_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#=[batch_size,1,pad_len,emb_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmax_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-b2b579a7ab64>\u001b[0m in \u001b[0;36mconv_block\u001b[0;34m(self, input, conv_layer)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# activation.size() = (batch_size, out_channels, dim1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmax_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# maxpool_out.size() = (batch_size, out_channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     return torch.max_pool1d(\n\u001b[0;32m--> 496\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m max_pool1d = boolean_dispatch(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 4-dimensional tensor for argument #1 'self' (while checking arguments for max_pool1d)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb4bXVEU4LCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ConvNet(5000,100)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRb1uVn95cqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  train_loss = 0\n",
        "  total = 0\n",
        "  for i, (text, labels) in enumerate(trainloader):\n",
        "    text = text.long()\n",
        "    labels = labels.long()\n",
        "    optimizer.zero_grad() # zero the gradient buffer ??\n",
        "    output = model(text)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()*labels.shape[0]\n",
        "    total += labels.shape[0]\n",
        "  print('epoch:', epoch+1, '; train_loss:' , train_loss/total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQel5msV3g-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_func(data):\n",
        "  train_loss = 0\n",
        "  train_auc = 0\n",
        "  for text, labels in enumerate(data):\n",
        "    optimizer.zero_grad() #???\n",
        "    text = text.long() #???\n",
        "    output = model(text)\n",
        "    loss = criterion(output, labels)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "  scheduler.step()\n",
        "  return train_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MAaBzuJ5F_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 5\n",
        "for epoch in range(N_EPOCHS):\n",
        "  train_loss = train_func(trainloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8n8Bevx3GZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_func(sub_train_):\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      collate_fn=generate_batch)\n",
        "    for i, (text, offsets, cls) in enumerate(data):\n",
        "        optimizer.zero_grad()\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        output = model(text, offsets)\n",
        "        loss = criterion(output, cls)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(sub_train_), train_acc / len(sub_train_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsmvDZj6-cuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "Xinput = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss(Xinput, target)\n",
        "output.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRVhUrPF-krB",
        "colab_type": "code",
        "outputId": "f23640b2-aa03-4b63-90df-eb56251a94e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Xinput"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6642,  0.0803, -0.4983, -1.0937, -0.6221],\n",
              "        [-0.8313, -0.3897, -0.0465, -0.5053, -0.5417],\n",
              "        [-0.5989, -0.1474,  0.8835,  0.3082,  1.0984]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E9DOfzr-iVK",
        "colab_type": "code",
        "outputId": "b543558d-582d-4a99-cc75-ab76523d2008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}