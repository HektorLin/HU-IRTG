{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DApp_calssification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3paWtjVD4Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnuPCxHGL7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "dler = nltk.downloader.Downloader()\n",
        "dler._update_index()\n",
        "dler.download('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-JK4yXs4SZx",
        "colab_type": "text"
      },
      "source": [
        "# File loading, Train-test-split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I21OjFQf2rOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.sparse import hstack\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "seed = int(time.strftime(\"%Y%m%d\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw03WHmJELWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/sol_classification.pickle'\n",
        "data = pickle.load(open(path, \"rb\"))\n",
        "data.comments = data.comments.apply('\\n'.join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJoPpvoM4rlh",
        "colab_type": "code",
        "outputId": "e2f1cabe-cdd0-463c-c963-d4d57b45cfc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# suppress categories with freq less than 2%\n",
        "freq = data['category'].value_counts(normalize=True)\n",
        "data['category'].replace(to_replace=list(freq[freq<0.02].index),value='others',inplace=True)\n",
        "data['category'].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "games           0.268832\n",
              "exchanges       0.216102\n",
              "finance         0.156309\n",
              "gambling        0.093691\n",
              "others          0.056026\n",
              "high-risk       0.044727\n",
              "marketplaces    0.039077\n",
              "social          0.036723\n",
              "development     0.033427\n",
              "media           0.031544\n",
              "property        0.023540\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjJlAu8lFuZc",
        "colab_type": "code",
        "outputId": "836bdac0-30c0-47af-f1b2-90c2fcf5c383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# dummy coding for target variables\n",
        "dummies = data['category'].str.get_dummies()\n",
        "X = data.loc[:,('source_code','uncommented','comments')]\n",
        "dummies.shape, X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2124, 11), (2124, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0BZeVlgxSGn",
        "colab_type": "code",
        "outputId": "5328da49-7090-443a-e505-4e90f7747109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, dummies, test_size = 0.25, random_state = seed, stratify=data.category)\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1593, 3), (531, 3), (1593, 11), (531, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "42a962ad-9082-436b-ab6c-d3eaf9db7964",
        "id": "mKXjTXgnZ6q-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "comment_len = X_train['comments'].apply(lambda x: len([line for line in x.split('\\n') if line.strip() != '']))\n",
        "comment_len.hist()\n",
        "comment_len.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234.3019460138104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbrhHmH2D5-L",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW7yAaQRuQXZ",
        "colab_type": "text"
      },
      "source": [
        "## Non-NLP features:\n",
        "length of comments, length of codes and the comment/code ratio\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgQPnaPCrdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def X_non_NLP_features (X):\n",
        "  code_len = X['uncommented'].apply(lambda x: len([line for line in x.split('\\n') if line.strip() != '']))\n",
        "  X = X.assign(code_len = code_len)\n",
        "\n",
        "  comment_len = X['comments'].apply(lambda x: len([line for line in x.split('\\n') if line.strip() != '']))\n",
        "  X = X.assign(comment_len = comment_len)\n",
        "\n",
        "  comment_ratio = comment_len/code_len\n",
        "  X = X.assign(comment_ratio = comment_ratio)\n",
        "\n",
        "  X.drop(labels=['source_code','uncommented','comments'],axis=1,inplace=True)\n",
        "  return np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9etCIKuV-e",
        "colab_type": "text"
      },
      "source": [
        "## NLP bag-of-word(BOW) tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqHX66AkFfnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NLP imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tc2ekJuQVkAc",
        "colab": {}
      },
      "source": [
        "my_stopwords = stopwords.words(\"english\")\n",
        "my_stopwords.append(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqYKvUA9l_46",
        "colab_type": "code",
        "outputId": "d3c054c5-57fc-46a6-b1d0-df61d9ef2317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "corpus = ' '.join(X_train[0:20]['comments'].values)\n",
        "new_words = regex_tokenizer.tokenize(corpus)\n",
        "\n",
        "new_words = sum([word.split('_') for word in new_words],[])\n",
        "new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words]\n",
        "new_words = sum(new_words, [])\n",
        "\n",
        "fdist1 = nltk.FreqDist(new_words)\n",
        "fdist1.most_common(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 1348),\n",
              " ('to', 792),\n",
              " ('of', 526),\n",
              " ('token', 489),\n",
              " ('@param', 406),\n",
              " ('@dev', 397),\n",
              " ('a', 338),\n",
              " ('address', 320),\n",
              " ('is', 307),\n",
              " ('owner', 219),\n",
              " ('contract', 217),\n",
              " ('be', 203),\n",
              " ('tokens', 192),\n",
              " ('amount', 189),\n",
              " ('in', 181),\n",
              " ('The', 174),\n",
              " ('that', 168),\n",
              " ('by', 165),\n",
              " ('if', 147),\n",
              " ('for', 145),\n",
              " ('ERC', 145),\n",
              " ('and', 143),\n",
              " ('from', 141),\n",
              " ('ID', 134),\n",
              " ('connector', 122),\n",
              " ('function', 121),\n",
              " ('this', 116),\n",
              " ('an', 114),\n",
              " ('transfer', 113),\n",
              " ('@return', 113),\n",
              " ('on', 107),\n",
              " ('new', 105),\n",
              " ('given', 96),\n",
              " ('not', 93),\n",
              " ('uint', 92),\n",
              " ('Token', 79),\n",
              " ('value', 72),\n",
              " ('it', 71),\n",
              " ('will', 68),\n",
              " ('can', 68),\n",
              " ('s', 67),\n",
              " ('only', 67),\n",
              " ('balance', 67),\n",
              " ('return', 67),\n",
              " ('which', 66),\n",
              " ('conversion', 66),\n",
              " ('when', 65),\n",
              " ('called', 65),\n",
              " ('sender', 62),\n",
              " ('bytes', 62),\n",
              " ('account', 61),\n",
              " ('or', 61),\n",
              " ('Id', 61),\n",
              " ('with', 60),\n",
              " ('contracts', 59),\n",
              " ('operator', 55),\n",
              " ('number', 51),\n",
              " ('Returns', 49),\n",
              " ('https', 48),\n",
              " ('call', 48),\n",
              " ('spender', 48),\n",
              " ('P', 48),\n",
              " ('@title', 47),\n",
              " ('ownership', 47),\n",
              " ('@notice', 47),\n",
              " ('zero', 46),\n",
              " ('as', 44),\n",
              " ('This', 43),\n",
              " ('returns', 43),\n",
              " ('list', 43),\n",
              " ('functions', 42),\n",
              " ('allowance', 41),\n",
              " ('than', 41),\n",
              " ('keccak', 41),\n",
              " ('one', 40),\n",
              " ('transaction', 40),\n",
              " ('fee', 40),\n",
              " ('interface', 39),\n",
              " ('com', 39),\n",
              " ('two', 39),\n",
              " ('overflow', 39),\n",
              " ('allows', 38),\n",
              " ('smart', 38),\n",
              " ('github', 37),\n",
              " ('approved', 37),\n",
              " ('index', 37),\n",
              " ('sol', 35),\n",
              " ('no', 34),\n",
              " ('total', 34),\n",
              " ('set', 34),\n",
              " ('price', 34),\n",
              " ('are', 33),\n",
              " ('use', 33),\n",
              " ('data', 33),\n",
              " ('msg', 33),\n",
              " ('d', 33),\n",
              " ('b', 32),\n",
              " ('t', 32),\n",
              " ('controller', 32),\n",
              " ('whether', 31)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZwEVle4pEWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_tokenizer (text):\n",
        "  \n",
        "  #tokenize\n",
        "  regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "  new_words = regex_tokenizer.tokenize(text)\n",
        "\n",
        "  #remove numbers\n",
        "  new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "\n",
        "  #split additionally by under_score\n",
        "  new_words = sum([word.split('_') for word in new_words],[])\n",
        "\n",
        "  #clear camelCase\n",
        "  new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words]\n",
        "  new_words = sum(new_words, [])\n",
        "\n",
        "  return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjml85NG6Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words = my_stopwords, tokenizer = my_tokenizer, lowercase = True,\n",
        "                max_features =1000, smooth_idf=True, analyzer = 'word')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlMQ0_DfueAO",
        "colab_type": "text"
      },
      "source": [
        "## Word-to-Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN0eP1yvPDJv",
        "colab_type": "code",
        "outputId": "227c51ad-3b74-44a6-f6e8-b456956ff939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJ6nQ6beoWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define my W2V tokenizor\n",
        "def build_corpus (list_of_text):\n",
        "\n",
        "  corpus = []\n",
        "\n",
        "  regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "  my_stopwords = stopwords.words(\"english\")\n",
        "  my_stopwords.append(\"\")\n",
        "\n",
        "  for i in range(0,len(list_of_text)):\n",
        "    text = list_of_text[i]\n",
        "    text = regex_tokenizer.tokenize(text)\n",
        "    text = sum([word.split('_') for word in text],[])\n",
        "    text = [re.sub('[0-9]','', word) for word in text]\n",
        "    text = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in text]\n",
        "    text = sum(text, [])\n",
        "\n",
        "    text = [w for w in text if not w in my_stopwords]\n",
        "    W2V_corpus.append(text)\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHyA_nw9rVVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build corpus base on the train comments\n",
        "W2V_train_corpus = build_corpus(X_train['comments'].values)\n",
        "W2V_test_corpus = build_corpus(X_test['comments'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCmS7BXO6RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build dictionary on the train comments corpus\n",
        "tokenizer_obj=Tokenizer(num_words=1000, lower=True)\n",
        "tokenizer_obj.fit_on_texts(W2V_train_corpus)\n",
        "\n",
        "# tokenize the train and the test set\n",
        "W2V_seq=tokenizer_obj.texts_to_sequences(W2V_train_corpus)\n",
        "W2V_test_seq=tokenizer_obj.texts_to_sequences(W2V_test_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgyojuMcZbph",
        "colab_type": "code",
        "outputId": "7eda9eb0-a2ca-40e2-cfb6-7807b8b93440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# show the vocabulary size and stat for comments\n",
        "word_index=tokenizer_obj.word_index\n",
        "print('vocab size: ',len(word_index))\n",
        "\n",
        "comment_len = np.array([len(comments) for comments in W2V_seq])\n",
        "print('Max comment length: ',comment_len.max())\n",
        "print('Mean comment length: ',int(comment_len.mean()))\n",
        "print('SD of comment length: ',int(np.std(comment_len)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size:  11464\n",
            "Max comment length:  7607\n",
            "Mean comment length:  841\n",
            "SD of comment length:  1099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6jrp96CTKab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decide on the max length to cover\n",
        "maxlen = 2000\n",
        "W2V_train_seq=pad_sequences(W2V_seq,maxlen=maxlen)\n",
        "W2V_test_seq=pad_sequences(W2V_test_seq,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDNV_bRAvnXZ",
        "colab_type": "code",
        "outputId": "75721ee0-73d9-463f-8738-a8bde9931ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W2V_train_seq.shape,W2V_test_seq.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1593, 2000), (531, 2000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgR7R9ywvdW6",
        "colab_type": "text"
      },
      "source": [
        "### Alternative Pre-trained Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9GyO163ZnR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBNYwkn9se7F",
        "colab_type": "code",
        "outputId": "98e5faf2-3821-4c3d-dbae-47ac59dbded4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# download the pre-trained weights\n",
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-19 08:16:38--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.93.221\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.93.221|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  47.8MB/s    in 33s     \n",
            "\n",
            "2020-04-19 08:17:12 (47.1 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zodYvSBitFYm",
        "colab_type": "code",
        "outputId": "55510366-3f4e-4501-d38d-0ae6cfb43033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# store it in the W2V format\n",
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "googlenews_w2v = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZexf6dvv08t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the W2V weight matrix\n",
        "googlenews_w2v_matrix = np.zeros((len(word_index) + 1, 300))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Oi6Czv5zF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the vocabulary\n",
        "key = list(googlenews_w2v.vocab.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-5TOO3wKOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fill in the W2V weight matrix\n",
        "for word,i in word_index.items():\n",
        "  if word in key:\n",
        "    googlenews_w2v_matrix[i] = googlenews_w2v.get_vector(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd4blqlM6RY4",
        "colab_type": "text"
      },
      "source": [
        "# Models based on BOW: logit, lightbm, multilayer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDFmD09rAdfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/params_search.pickle'\n",
        "DApps_model_params = pickle.load(open(path, \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F3FuvDUC37Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logit model\n",
        "def logit_model (X_train,y_train,params):\n",
        "  #logreg = LogisticRegression(penalty=params['penalty'],max_iter=1000)\n",
        "  logreg = LogisticRegression(penalty=params['penalty'],C=params['C'],max_iter=10000)\n",
        "  logreg.fit(X_train, y_train)\n",
        "  return logreg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHWleBX7j6Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lightbm model\n",
        "def lightbm_model (X_train,y_train,params):\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = seed, stratify=y_train)\n",
        "\n",
        "  train_data = lgb.Dataset(X_train,label=y_train)\n",
        "  validation_data = lgb.Dataset(X_val,label=y_val)\n",
        "\n",
        "  params.update([('objective','binary'),('metric','auc')])\n",
        "  num_round = 100\n",
        "  bst = lgb.train(params, train_data, num_round, valid_sets=validation_data,verbose_eval=False,early_stopping_rounds=5)\n",
        "\n",
        "  return bst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfie5pcv_XDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model (X_train,y_train,params):\n",
        "  mlp_classifier = MLPClassifier(hidden_layer_sizes=params['hidden_layer_sizes'],solver=params['solver'],early_stopping=True,max_iter=10000)\n",
        "  mlp_classifier.fit(X_train, y_train)\n",
        "  return mlp_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn8XCUpTuFz7",
        "colab_type": "code",
        "outputId": "c603c3bc-8b62-4a55-a576-cd798bec57f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# cross_validation for opt params\n",
        "DApps_model_params = {}\n",
        "DApps_model_score = {}\n",
        "for DApp_type in data['category'].value_counts().index:\n",
        "\n",
        "  y_train = np.array(Y_train[DApp_type])\n",
        "  X_train_xNLP = np.array(X_non_NLP_features(X_train))\n",
        "  X_train_NLP = vectorizer.fit_transform(X_train['comments'])\n",
        "  X_train_CV = hstack((X_train_xNLP,X_train_NLP)).toarray()\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_CV = scaler.fit_transform(X_train_CV)\n",
        "\n",
        "  params_dist = {'logit':{'penalty':['l1','l2'],'C':[0.5,1,2]},\n",
        "           'lightbm':{'num_leaves':[32, 64, 128]},\n",
        "           'mlp':{'hidden_layer_sizes':[(64,32),(128,32),(256,32)],\n",
        "               'solver':['adam'],\n",
        "               'n_iter_no_change':[5]}}\n",
        "\n",
        "  #print('Fitting logit')\n",
        "  logit_classifier = LogisticRegression(max_iter=10000)\n",
        "  logit_search = RandomizedSearchCV(logit_classifier, param_distributions=params_dist['logit'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  logit_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  #print('Fitting lightbm')\n",
        "  lgb_classifier = lgb.LGBMClassifier()\n",
        "  #lgb_search = GridSearchCV(lgb_classifier, param_grid=params_dist['lightbm'], cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  lgb_search = RandomizedSearchCV(lgb_classifier, param_distributions=params_dist['lightbm'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  lgb_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  #print('Fitting MLP')\n",
        "  mlp_classifier = MLPClassifier(early_stopping=True,max_iter=10000)\n",
        "  #mlp_search = GridSearchCV(mlp_classifier, param_grid=params_dist['mlp'], cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  mlp_search = RandomizedSearchCV(mlp_classifier, param_distributions=params_dist['mlp'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  mlp_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  searches = {'logit_params':logit_search.best_params_,'lgb_params':lgb_search.best_params_,'mlp_params':mlp_search.best_params_}\n",
        "  DApps_model_params.update([(DApp_type,searches)])\n",
        "  scores = {'logit_score':logit_search.best_score_,'lgb_score':lgb_search.best_score_,'mlp_score':mlp_search.best_score_}\n",
        "  DApps_model_score.update([(DApp_type,scores)])\n",
        "\n",
        "with open('params_search.pickle', 'wb') as handle:\n",
        "  pickle.dump(DApps_model_params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSAZ2LUPX_h",
        "colab_type": "code",
        "outputId": "90ddd6c5-1731-42f2-f00d-7b16fbd580aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "table_cv = []\n",
        "for DApp_type in DApps_model_score:\n",
        "  cv_aucs = [cv_score for cv_score in DApps_model_score[DApp_type].values()]\n",
        "  cv_aucs.append(DApp_type)\n",
        "  table_cv.append(cv_aucs)\n",
        "\n",
        "table_cv\n",
        "table_cv = pd.DataFrame(table_cv)\n",
        "table_cv.columns = ['logit_cv','lightbm_cv','mlp_cv','category']\n",
        "table_cv.set_index('category',inplace=True)\n",
        "table_cv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit_cv</th>\n",
              "      <th>lightbm_cv</th>\n",
              "      <th>mlp_cv</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.900635</td>\n",
              "      <td>0.912480</td>\n",
              "      <td>0.900090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.959379</td>\n",
              "      <td>0.955496</td>\n",
              "      <td>0.954687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.904681</td>\n",
              "      <td>0.908626</td>\n",
              "      <td>0.892875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.888100</td>\n",
              "      <td>0.900053</td>\n",
              "      <td>0.885413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.842408</td>\n",
              "      <td>0.839435</td>\n",
              "      <td>0.614871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.905709</td>\n",
              "      <td>0.896943</td>\n",
              "      <td>0.747480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.774803</td>\n",
              "      <td>0.754351</td>\n",
              "      <td>0.580236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.762166</td>\n",
              "      <td>0.722853</td>\n",
              "      <td>0.605930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.820489</td>\n",
              "      <td>0.813542</td>\n",
              "      <td>0.605416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.816791</td>\n",
              "      <td>0.768849</td>\n",
              "      <td>0.573995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.819428</td>\n",
              "      <td>0.787029</td>\n",
              "      <td>0.537507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              logit_cv  lightbm_cv    mlp_cv\n",
              "category                                    \n",
              "games         0.900635    0.912480  0.900090\n",
              "exchanges     0.959379    0.955496  0.954687\n",
              "finance       0.904681    0.908626  0.892875\n",
              "gambling      0.888100    0.900053  0.885413\n",
              "others        0.842408    0.839435  0.614871\n",
              "high-risk     0.905709    0.896943  0.747480\n",
              "marketplaces  0.774803    0.754351  0.580236\n",
              "social        0.762166    0.722853  0.605930\n",
              "development   0.820489    0.813542  0.605416\n",
              "media         0.816791    0.768849  0.573995\n",
              "property      0.819428    0.787029  0.537507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K83P8DTUIZSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main function\n",
        "\n",
        "test_aucs = []\n",
        "for DApp_type in data['category'].value_counts().index:\n",
        "  y_train = np.array(Y_train[DApp_type])\n",
        "  y_test = np.array(Y_test[DApp_type])\n",
        "\n",
        "  X_train_xNLP = np.array(X_non_NLP_features(X_train))\n",
        "  X_train_NLP = vectorizer.fit_transform(X_train['comments'])\n",
        "  X_train_set = hstack((X_train_xNLP,X_train_NLP)).toarray()\n",
        "\n",
        "  X_test_xNLP = np.array(X_non_NLP_features(X_test))\n",
        "  X_test_NLP = vectorizer.transform(X_test['comments'])\n",
        "  X_test_set = hstack((X_test_xNLP,X_test_NLP)).toarray()\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_set = scaler.fit_transform(X_train_set)\n",
        "  X_test_set = scaler.transform(X_test_set)\n",
        "\n",
        "  logit = logit_model(X_train_set,y_train,models_search[DApp_type]['logit_params'])\n",
        "  lightbm = lightbm_model(X_train_set,y_train,models_search[DApp_type]['lgb_params'])\n",
        "  mlp = mlp_model(X_train_set,y_train,models_search[DApp_type]['mlp_params'])\n",
        "\n",
        "  test_aucs.append([DApp_type,roc_auc_score(y_test,logit.predict(X_test_set)),roc_auc_score(y_test,lightbm.predict(X_test_set)),roc_auc_score(y_test,[x[1] for x in mlp.predict_proba(X_test_set)])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz8HZikIS7nU",
        "colab_type": "code",
        "outputId": "de6e382c-4501-4452-d32f-20eb49e78bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# output\n",
        "table_test = pd.DataFrame(test_aucs)\n",
        "table_test.columns = ['category','logit','lightbm','mlp']\n",
        "table_test.set_index('category',inplace=True)\n",
        "table_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit</th>\n",
              "      <th>lightbm</th>\n",
              "      <th>mlp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.806944</td>\n",
              "      <td>0.919544</td>\n",
              "      <td>0.906730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.899540</td>\n",
              "      <td>0.937949</td>\n",
              "      <td>0.961716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.738059</td>\n",
              "      <td>0.892642</td>\n",
              "      <td>0.864202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.738960</td>\n",
              "      <td>0.835281</td>\n",
              "      <td>0.880790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.531337</td>\n",
              "      <td>0.784331</td>\n",
              "      <td>0.799468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.694668</td>\n",
              "      <td>0.884201</td>\n",
              "      <td>0.932557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.759150</td>\n",
              "      <td>0.795798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.498047</td>\n",
              "      <td>0.639597</td>\n",
              "      <td>0.752981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.779186</td>\n",
              "      <td>0.800032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.528439</td>\n",
              "      <td>0.718986</td>\n",
              "      <td>0.734321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.539740</td>\n",
              "      <td>0.645793</td>\n",
              "      <td>0.808847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 logit   lightbm       mlp\n",
              "category                                  \n",
              "games         0.806944  0.919544  0.906730\n",
              "exchanges     0.899540  0.937949  0.961716\n",
              "finance       0.738059  0.892642  0.864202\n",
              "gambling      0.738960  0.835281  0.880790\n",
              "others        0.531337  0.784331  0.799468\n",
              "high-risk     0.694668  0.884201  0.932557\n",
              "marketplaces  0.595238  0.759150  0.795798\n",
              "social        0.498047  0.639597  0.752981\n",
              "development   0.583333  0.779186  0.800032\n",
              "media         0.528439  0.718986  0.734321\n",
              "property      0.539740  0.645793  0.808847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFkJGMicidr0",
        "colab_type": "code",
        "outputId": "75a7f8bd-8ec5-40a2-dd4a-1cfd751bc9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "table = table_test.join(table_cv)\n",
        "table.loc[:,('logit_cv','logit','lightbm_cv','lightbm','mlp_cv','mlp')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit_cv</th>\n",
              "      <th>logit</th>\n",
              "      <th>lightbm_cv</th>\n",
              "      <th>lightbm</th>\n",
              "      <th>mlp_cv</th>\n",
              "      <th>mlp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.903527</td>\n",
              "      <td>0.806944</td>\n",
              "      <td>0.912480</td>\n",
              "      <td>0.919544</td>\n",
              "      <td>0.886719</td>\n",
              "      <td>0.906730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.959379</td>\n",
              "      <td>0.899540</td>\n",
              "      <td>0.955496</td>\n",
              "      <td>0.937949</td>\n",
              "      <td>0.946653</td>\n",
              "      <td>0.961716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.904681</td>\n",
              "      <td>0.738059</td>\n",
              "      <td>0.908626</td>\n",
              "      <td>0.892642</td>\n",
              "      <td>0.875982</td>\n",
              "      <td>0.864202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.887796</td>\n",
              "      <td>0.738960</td>\n",
              "      <td>0.900053</td>\n",
              "      <td>0.835281</td>\n",
              "      <td>0.888690</td>\n",
              "      <td>0.880790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.845451</td>\n",
              "      <td>0.531337</td>\n",
              "      <td>0.839435</td>\n",
              "      <td>0.784331</td>\n",
              "      <td>0.818368</td>\n",
              "      <td>0.799468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.905216</td>\n",
              "      <td>0.694668</td>\n",
              "      <td>0.896943</td>\n",
              "      <td>0.884201</td>\n",
              "      <td>0.864426</td>\n",
              "      <td>0.932557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.774803</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.754351</td>\n",
              "      <td>0.759150</td>\n",
              "      <td>0.764272</td>\n",
              "      <td>0.795798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.758435</td>\n",
              "      <td>0.498047</td>\n",
              "      <td>0.722853</td>\n",
              "      <td>0.639597</td>\n",
              "      <td>0.744929</td>\n",
              "      <td>0.752981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.820489</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.813542</td>\n",
              "      <td>0.779186</td>\n",
              "      <td>0.754994</td>\n",
              "      <td>0.800032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.816791</td>\n",
              "      <td>0.528439</td>\n",
              "      <td>0.768849</td>\n",
              "      <td>0.718986</td>\n",
              "      <td>0.748617</td>\n",
              "      <td>0.734321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.819428</td>\n",
              "      <td>0.539740</td>\n",
              "      <td>0.787029</td>\n",
              "      <td>0.645793</td>\n",
              "      <td>0.791999</td>\n",
              "      <td>0.808847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              logit_cv     logit  lightbm_cv   lightbm    mlp_cv       mlp\n",
              "category                                                                  \n",
              "games         0.903527  0.806944    0.912480  0.919544  0.886719  0.906730\n",
              "exchanges     0.959379  0.899540    0.955496  0.937949  0.946653  0.961716\n",
              "finance       0.904681  0.738059    0.908626  0.892642  0.875982  0.864202\n",
              "gambling      0.887796  0.738960    0.900053  0.835281  0.888690  0.880790\n",
              "others        0.845451  0.531337    0.839435  0.784331  0.818368  0.799468\n",
              "high-risk     0.905216  0.694668    0.896943  0.884201  0.864426  0.932557\n",
              "marketplaces  0.774803  0.595238    0.754351  0.759150  0.764272  0.795798\n",
              "social        0.758435  0.498047    0.722853  0.639597  0.744929  0.752981\n",
              "development   0.820489  0.583333    0.813542  0.779186  0.754994  0.800032\n",
              "media         0.816791  0.528439    0.768849  0.718986  0.748617  0.734321\n",
              "property      0.819428  0.539740    0.787029  0.645793  0.791999  0.808847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRYoh7TYsiq",
        "colab_type": "text"
      },
      "source": [
        "# Sequential Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3TIUkbKisMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Conv1D,Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvBHH_aSSDFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# additional step: prepare and scale the nonNLP features\n",
        "X_train_xNLP = np.array(X_non_NLP_features(X_train))\n",
        "scaler = MinMaxScaler()\n",
        "X_train_set = scaler.fit_transform(X_train_xNLP)\n",
        "\n",
        "X_test_xNLP = np.array(X_non_NLP_features(X_test))\n",
        "X_test_set = scaler.transform(X_test_xNLP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPXgKzFOQBgk",
        "colab_type": "code",
        "outputId": "1c6ebbf6-bf1d-42a9-8d3a-046c4ba42ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "input_NLP = Input(shape=(2000,))\n",
        "input_nonNLP = Input(shape=(3,))\n",
        "\n",
        "embedding_layer = Embedding(input_dim=len(word_index)+1,output_dim=100,input_length=maxlen,trainable=True)\n",
        "#embedding_layer = Embedding(input_dim=len(word_index)+1,output_dim=300,weights=[googlenews_w2v_matrix],input_length=maxSentenceLength,trainable=False)\n",
        "\n",
        "NLP = embedding_layer(input_NLP)\n",
        "NLP = GRU(64,activation='relu')(NLP)\n",
        "NLP = Dense(32,activation='relu')(NLP)\n",
        "\n",
        "xNLP = Dense(8,activation='relu')(input_nonNLP)\n",
        "\n",
        "merged = keras.layers.concatenate([NLP,xNLP], axis=1)\n",
        "merged = Dense(32,activation='tanh')(merged)\n",
        "predictions = Dense(11,activation='softmax')(merged)\n",
        "\n",
        "model = Model(inputs=[input_NLP,input_nonNLP], outputs=predictions)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           (None, 2000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_16 (Embedding)        (None, 2000, 100)    1146500     input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gru_14 (GRU)                    (None, 64)           31680       embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_30 (InputLayer)           (None, 3)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 32)           2080        gru_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 8)            32          input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 40)           0           dense_45[0][0]                   \n",
            "                                                                 dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 32)           1312        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 11)           363         dense_47[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,181,967\n",
            "Trainable params: 1,181,967\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3RXj_i7ibHG",
        "colab_type": "code",
        "outputId": "03554500-069d-4cd8-c992-de8c30c303af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "cb=EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=2, restore_best_weights=True)\n",
        "\n",
        "model.fit([W2V_seq,X_train_set], np.array(Y_train),\n",
        "      batch_size=50, epochs=200, verbose=1,\n",
        "      #validation_data=(X_test, y_test.reshape(-1,y_test.shape[1])),\n",
        "      validation_split=0.25,\n",
        "      callbacks=[cb],shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1194 samples, validate on 399 samples\n",
            "Epoch 1/200\n",
            "1194/1194 [==============================] - 55s 46ms/step - loss: 2.3258 - val_loss: 2.1917\n",
            "Epoch 2/200\n",
            "1194/1194 [==============================] - 53s 45ms/step - loss: 2.0091 - val_loss: 1.8604\n",
            "Epoch 3/200\n",
            "1194/1194 [==============================] - 53s 45ms/step - loss: 1.7038 - val_loss: 1.6855\n",
            "Epoch 4/200\n",
            "1194/1194 [==============================] - 53s 45ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/200\n",
            "1194/1194 [==============================] - 53s 45ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7e8f212f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKgrbM0pafH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = model.predict([W2V_test_seq,X_test_set])\n",
        "Y_pred = pd.DataFrame(Y_pred,columns=Y_train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSpfni8bbap",
        "colab_type": "code",
        "outputId": "6832d9d1-dacc-4181-b6f9-b527b349bce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "table = []\n",
        "for DApp in Y_train.columns:\n",
        "  table.append([DApp,roc_auc_score(Y_test[DApp],Y_pred[DApp])])\n",
        "\n",
        "table = pd.DataFrame(table)\n",
        "table.columns = ['category','GRU']\n",
        "table.set_index('category',inplace=True)\n",
        "table.loc[data['category'].value_counts().index,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.745710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.876839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.734469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.786029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.683200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.505917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.493542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.702508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.687622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.565003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.732177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   GRU\n",
              "games         0.745710\n",
              "exchanges     0.876839\n",
              "finance       0.734469\n",
              "gambling      0.786029\n",
              "others        0.683200\n",
              "high-risk     0.505917\n",
              "marketplaces  0.493542\n",
              "social        0.702508\n",
              "development   0.687622\n",
              "media         0.565003\n",
              "property      0.732177"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwl0yTFtq7w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}