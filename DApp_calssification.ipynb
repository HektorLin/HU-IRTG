{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DApp_calssification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3paWtjVD4Gd",
        "colab_type": "code",
        "outputId": "b2cccbf8-9534-4814-dd17-09d2f80b67a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnuPCxHGL7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "dler = nltk.downloader.Downloader()\n",
        "dler._update_index()\n",
        "dler.download('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-JK4yXs4SZx",
        "colab_type": "text"
      },
      "source": [
        "# File loading, Train-test-split, result table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I21OjFQf2rOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.sparse import hstack\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "seed = int(time.strftime(\"%Y%m%d\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw03WHmJELWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/sol_classification.pickle'\n",
        "data = pickle.load(open(path, \"rb\"))\n",
        "data.comments = data.comments.apply('\\n'.join)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJoPpvoM4rlh",
        "colab_type": "code",
        "outputId": "2b282ecc-9e12-44e2-aa84-f22a17da0515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# suppress categories with freq less than 2%\n",
        "freq = data['category'].value_counts(normalize=True)\n",
        "data['category'].replace(to_replace=list(freq[freq<0.02].index),value='others',inplace=True)\n",
        "data['category'].value_counts(normalize=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "games           0.268832\n",
              "exchanges       0.216102\n",
              "finance         0.156309\n",
              "gambling        0.093691\n",
              "others          0.056026\n",
              "high-risk       0.044727\n",
              "marketplaces    0.039077\n",
              "social          0.036723\n",
              "development     0.033427\n",
              "media           0.031544\n",
              "property        0.023540\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjJlAu8lFuZc",
        "colab_type": "code",
        "outputId": "3802f3b6-078b-4983-f98b-1089e5576725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# dummy coding for target variables\n",
        "dummies = data['category'].str.get_dummies()\n",
        "X = data.loc[:,('source_code','uncommented','comments')]\n",
        "dummies.shape, X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2124, 11), (2124, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0BZeVlgxSGn",
        "colab_type": "code",
        "outputId": "58d70cd2-5abe-403f-f412-33c665c34fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, dummies, test_size = 0.25, random_state = seed, stratify=data.category)\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1593, 3), (531, 3), (1593, 11), (531, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2v6r7A79o85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initiate result matrixs for cv and the test set\n",
        "\n",
        "iterables = [['comments_only', 'codes_only', 'combined'], #input type\n",
        "        ['logit','lightbm','mlp','GRU','CNN'], #model types  \n",
        "        data['category'].value_counts().index, #category\n",
        "        ] \n",
        "\n",
        "index = pd.MultiIndex.from_product(iterables, names=['input_types','models','categories'])\n",
        "result = pd.DataFrame(index=index)\n",
        "result['AUC'] = None\n",
        "result.reset_index(inplace=True)\n",
        "cv_result = result.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMOFBAI3xH7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.read_csv('/content/drive/My Drive/Colab Notebooks/test_auc.csv')\n",
        "cv_result = pd.read_csv('/content/drive/My Drive/Colab Notebooks/validation_auc.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW7yAaQRuQXZ",
        "colab_type": "text"
      },
      "source": [
        "# Non-NLP\n",
        "length of comments, length of codes and the comment/code ratio\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgQPnaPCrdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def X_non_NLP_features (X):\n",
        "  code_len = X['uncommented'].apply(lambda x: len([line for line in x.split('\\n') if line.strip() != '']))\n",
        "  X = X.assign(code_len = code_len)\n",
        "\n",
        "  comment_len = X['comments'].apply(lambda x: len([line for line in x.split('\\n') if line.strip() != '']))\n",
        "  X = X.assign(comment_len = comment_len)\n",
        "\n",
        "  comment_ratio = comment_len/code_len\n",
        "  X = X.assign(comment_ratio = comment_ratio)\n",
        "\n",
        "  X.drop(labels=['source_code','uncommented','comments'],axis=1,inplace=True)\n",
        "  return np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9etCIKuV-e",
        "colab_type": "text"
      },
      "source": [
        "# BOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZc49Ht8IFef",
        "colab_type": "text"
      },
      "source": [
        "## BOW tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqHX66AkFfnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NLP imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tc2ekJuQVkAc",
        "colab": {}
      },
      "source": [
        "my_stopwords = stopwords.words(\"english\")\n",
        "my_stopwords.append(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs-Ti5IMJiSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check out the first 20 comments as a sample for tokenizing\n",
        "regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "corpus = ' '.join(X_train[0:20]['comments'].values)\n",
        "new_words = regex_tokenizer.tokenize(corpus)\n",
        "\n",
        "new_words = sum([word.split('_') for word in new_words],[])\n",
        "new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words] #split cramelCase\n",
        "new_words = sum(new_words, [])\n",
        "\n",
        "fdist1 = nltk.FreqDist(new_words)\n",
        "fdist1.most_common(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZwEVle4pEWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_tokenizer (text):\n",
        "  \n",
        "  #tokenize\n",
        "  regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "  new_words = regex_tokenizer.tokenize(text)\n",
        "\n",
        "  #remove numbers\n",
        "  new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "\n",
        "  #split additionally by under_score\n",
        "  new_words = sum([word.split('_') for word in new_words],[])\n",
        "\n",
        "  #clear camelCase\n",
        "  new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words]\n",
        "  new_words = sum(new_words, [])\n",
        "\n",
        "  return new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHjml85NG6Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words = my_stopwords, tokenizer = my_tokenizer, lowercase = True,\n",
        "                max_features =1000, smooth_idf=True, analyzer = 'word')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd4blqlM6RY4",
        "colab_type": "text"
      },
      "source": [
        "## Models based on BOW: logit, lightbm, multilayer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDFmD09rAdfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/params_search.pickle'\n",
        "DApps_model_params = pickle.load(open(path, \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F3FuvDUC37Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# logit model\n",
        "def logit_model (X_train,y_train,params):\n",
        "  #logreg = LogisticRegression(penalty=params['penalty'],max_iter=1000)\n",
        "  logreg = LogisticRegression(penalty=params['penalty'],C=params['C'],max_iter=10000)\n",
        "  logreg.fit(X_train, y_train)\n",
        "  return logreg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHWleBX7j6Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lightbm model\n",
        "def lightbm_model (X_train,y_train,params):\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = seed, stratify=y_train)\n",
        "\n",
        "  train_data = lgb.Dataset(X_train,label=y_train)\n",
        "  validation_data = lgb.Dataset(X_val,label=y_val)\n",
        "\n",
        "  params.update([('objective','binary'),('metric','auc')])\n",
        "  num_round = 100\n",
        "  bst = lgb.train(params, train_data, num_round, valid_sets=validation_data,verbose_eval=False,early_stopping_rounds=5)\n",
        "\n",
        "  return bst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfie5pcv_XDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model (X_train,y_train,params):\n",
        "  mlp_classifier = MLPClassifier(hidden_layer_sizes=params['hidden_layer_sizes'],solver=params['solver'],early_stopping=True,max_iter=10000)\n",
        "  mlp_classifier.fit(X_train, y_train)\n",
        "  return mlp_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn8XCUpTuFz7",
        "colab_type": "code",
        "outputId": "c603c3bc-8b62-4a55-a576-cd798bec57f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# cross_validation for opt params\n",
        "DApps_model_params = {}\n",
        "DApps_model_score = {}\n",
        "for DApp_type in data['category'].value_counts().index:\n",
        "\n",
        "  y_train = np.array(Y_train[DApp_type])\n",
        "  X_train_xNLP = np.array(X_non_NLP_features(X_train))\n",
        "  X_train_NLP = vectorizer.fit_transform(X_train['comments'])\n",
        "  X_train_CV = hstack((X_train_xNLP,X_train_NLP)).toarray()\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_CV = scaler.fit_transform(X_train_CV)\n",
        "\n",
        "  params_dist = {'logit':{'penalty':['l1','l2'],'C':[0.5,1,2]},\n",
        "           'lightbm':{'num_leaves':[32, 64, 128]},\n",
        "           'mlp':{'hidden_layer_sizes':[(64,32),(128,32),(256,32)],\n",
        "               'solver':['adam'],\n",
        "               'n_iter_no_change':[5]}}\n",
        "\n",
        "  #print('Fitting logit')\n",
        "  logit_classifier = LogisticRegression(max_iter=10000)\n",
        "  logit_search = RandomizedSearchCV(logit_classifier, param_distributions=params_dist['logit'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  logit_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  #print('Fitting lightbm')\n",
        "  lgb_classifier = lgb.LGBMClassifier()\n",
        "  #lgb_search = GridSearchCV(lgb_classifier, param_grid=params_dist['lightbm'], cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  lgb_search = RandomizedSearchCV(lgb_classifier, param_distributions=params_dist['lightbm'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  lgb_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  #print('Fitting MLP')\n",
        "  mlp_classifier = MLPClassifier(early_stopping=True,max_iter=10000)\n",
        "  #mlp_search = GridSearchCV(mlp_classifier, param_grid=params_dist['mlp'], cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  mlp_search = RandomizedSearchCV(mlp_classifier, param_distributions=params_dist['mlp'], n_iter=3, cv=3, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
        "  mlp_search.fit(X_train_CV,y_train)\n",
        "\n",
        "  searches = {'logit_params':logit_search.best_params_,'lgb_params':lgb_search.best_params_,'mlp_params':mlp_search.best_params_}\n",
        "  DApps_model_params.update([(DApp_type,searches)])\n",
        "  scores = {'logit_score':logit_search.best_score_,'lgb_score':lgb_search.best_score_,'mlp_score':mlp_search.best_score_}\n",
        "  DApps_model_score.update([(DApp_type,scores)])\n",
        "\n",
        "with open('params_search.pickle', 'wb') as handle:\n",
        "  pickle.dump(DApps_model_params, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxSAZ2LUPX_h",
        "colab_type": "code",
        "outputId": "90ddd6c5-1731-42f2-f00d-7b16fbd580aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "table_cv = []\n",
        "for DApp_type in DApps_model_score:\n",
        "  cv_aucs = [cv_score for cv_score in DApps_model_score[DApp_type].values()]\n",
        "  cv_aucs.append(DApp_type)\n",
        "  table_cv.append(cv_aucs)\n",
        "\n",
        "table_cv\n",
        "table_cv = pd.DataFrame(table_cv)\n",
        "table_cv.columns = ['logit_cv','lightbm_cv','mlp_cv','category']\n",
        "table_cv.set_index('category',inplace=True)\n",
        "table_cv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit_cv</th>\n",
              "      <th>lightbm_cv</th>\n",
              "      <th>mlp_cv</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.900635</td>\n",
              "      <td>0.912480</td>\n",
              "      <td>0.900090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.959379</td>\n",
              "      <td>0.955496</td>\n",
              "      <td>0.954687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.904681</td>\n",
              "      <td>0.908626</td>\n",
              "      <td>0.892875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.888100</td>\n",
              "      <td>0.900053</td>\n",
              "      <td>0.885413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.842408</td>\n",
              "      <td>0.839435</td>\n",
              "      <td>0.614871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.905709</td>\n",
              "      <td>0.896943</td>\n",
              "      <td>0.747480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.774803</td>\n",
              "      <td>0.754351</td>\n",
              "      <td>0.580236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.762166</td>\n",
              "      <td>0.722853</td>\n",
              "      <td>0.605930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.820489</td>\n",
              "      <td>0.813542</td>\n",
              "      <td>0.605416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.816791</td>\n",
              "      <td>0.768849</td>\n",
              "      <td>0.573995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.819428</td>\n",
              "      <td>0.787029</td>\n",
              "      <td>0.537507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              logit_cv  lightbm_cv    mlp_cv\n",
              "category                                    \n",
              "games         0.900635    0.912480  0.900090\n",
              "exchanges     0.959379    0.955496  0.954687\n",
              "finance       0.904681    0.908626  0.892875\n",
              "gambling      0.888100    0.900053  0.885413\n",
              "others        0.842408    0.839435  0.614871\n",
              "high-risk     0.905709    0.896943  0.747480\n",
              "marketplaces  0.774803    0.754351  0.580236\n",
              "social        0.762166    0.722853  0.605930\n",
              "development   0.820489    0.813542  0.605416\n",
              "media         0.816791    0.768849  0.573995\n",
              "property      0.819428    0.787029  0.537507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K83P8DTUIZSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main function\n",
        "\n",
        "test_aucs = []\n",
        "for DApp_type in data['category'].value_counts().index:\n",
        "  y_train = np.array(Y_train[DApp_type])\n",
        "  y_test = np.array(Y_test[DApp_type])\n",
        "\n",
        "  X_train_xNLP = np.array(X_non_NLP_features(X_train))\n",
        "  X_train_NLP = vectorizer.fit_transform(X_train['comments'])\n",
        "  X_train_set = hstack((X_train_xNLP,X_train_NLP)).toarray()\n",
        "\n",
        "  X_test_xNLP = np.array(X_non_NLP_features(X_test))\n",
        "  X_test_NLP = vectorizer.transform(X_test['comments'])\n",
        "  X_test_set = hstack((X_test_xNLP,X_test_NLP)).toarray()\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train_set = scaler.fit_transform(X_train_set)\n",
        "  X_test_set = scaler.transform(X_test_set)\n",
        "\n",
        "  logit = logit_model(X_train_set,y_train,models_search[DApp_type]['logit_params'])\n",
        "  lightbm = lightbm_model(X_train_set,y_train,models_search[DApp_type]['lgb_params'])\n",
        "  mlp = mlp_model(X_train_set,y_train,models_search[DApp_type]['mlp_params'])\n",
        "\n",
        "  test_aucs.append([DApp_type,roc_auc_score(y_test,logit.predict(X_test_set)),roc_auc_score(y_test,lightbm.predict(X_test_set)),roc_auc_score(y_test,[x[1] for x in mlp.predict_proba(X_test_set)])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz8HZikIS7nU",
        "colab_type": "code",
        "outputId": "de6e382c-4501-4452-d32f-20eb49e78bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# output\n",
        "table_test = pd.DataFrame(test_aucs)\n",
        "table_test.columns = ['category','logit','lightbm','mlp']\n",
        "table_test.set_index('category',inplace=True)\n",
        "table_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit</th>\n",
              "      <th>lightbm</th>\n",
              "      <th>mlp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.806944</td>\n",
              "      <td>0.919544</td>\n",
              "      <td>0.906730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.899540</td>\n",
              "      <td>0.937949</td>\n",
              "      <td>0.961716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.738059</td>\n",
              "      <td>0.892642</td>\n",
              "      <td>0.864202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.738960</td>\n",
              "      <td>0.835281</td>\n",
              "      <td>0.880790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.531337</td>\n",
              "      <td>0.784331</td>\n",
              "      <td>0.799468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.694668</td>\n",
              "      <td>0.884201</td>\n",
              "      <td>0.932557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.759150</td>\n",
              "      <td>0.795798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.498047</td>\n",
              "      <td>0.639597</td>\n",
              "      <td>0.752981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.779186</td>\n",
              "      <td>0.800032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.528439</td>\n",
              "      <td>0.718986</td>\n",
              "      <td>0.734321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.539740</td>\n",
              "      <td>0.645793</td>\n",
              "      <td>0.808847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 logit   lightbm       mlp\n",
              "category                                  \n",
              "games         0.806944  0.919544  0.906730\n",
              "exchanges     0.899540  0.937949  0.961716\n",
              "finance       0.738059  0.892642  0.864202\n",
              "gambling      0.738960  0.835281  0.880790\n",
              "others        0.531337  0.784331  0.799468\n",
              "high-risk     0.694668  0.884201  0.932557\n",
              "marketplaces  0.595238  0.759150  0.795798\n",
              "social        0.498047  0.639597  0.752981\n",
              "development   0.583333  0.779186  0.800032\n",
              "media         0.528439  0.718986  0.734321\n",
              "property      0.539740  0.645793  0.808847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFkJGMicidr0",
        "colab_type": "code",
        "outputId": "75a7f8bd-8ec5-40a2-dd4a-1cfd751bc9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "table = table_test.join(table_cv)\n",
        "table.loc[:,('logit_cv','logit','lightbm_cv','lightbm','mlp_cv','mlp')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit_cv</th>\n",
              "      <th>logit</th>\n",
              "      <th>lightbm_cv</th>\n",
              "      <th>lightbm</th>\n",
              "      <th>mlp_cv</th>\n",
              "      <th>mlp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.903527</td>\n",
              "      <td>0.806944</td>\n",
              "      <td>0.912480</td>\n",
              "      <td>0.919544</td>\n",
              "      <td>0.886719</td>\n",
              "      <td>0.906730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.959379</td>\n",
              "      <td>0.899540</td>\n",
              "      <td>0.955496</td>\n",
              "      <td>0.937949</td>\n",
              "      <td>0.946653</td>\n",
              "      <td>0.961716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.904681</td>\n",
              "      <td>0.738059</td>\n",
              "      <td>0.908626</td>\n",
              "      <td>0.892642</td>\n",
              "      <td>0.875982</td>\n",
              "      <td>0.864202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.887796</td>\n",
              "      <td>0.738960</td>\n",
              "      <td>0.900053</td>\n",
              "      <td>0.835281</td>\n",
              "      <td>0.888690</td>\n",
              "      <td>0.880790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.845451</td>\n",
              "      <td>0.531337</td>\n",
              "      <td>0.839435</td>\n",
              "      <td>0.784331</td>\n",
              "      <td>0.818368</td>\n",
              "      <td>0.799468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.905216</td>\n",
              "      <td>0.694668</td>\n",
              "      <td>0.896943</td>\n",
              "      <td>0.884201</td>\n",
              "      <td>0.864426</td>\n",
              "      <td>0.932557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.774803</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.754351</td>\n",
              "      <td>0.759150</td>\n",
              "      <td>0.764272</td>\n",
              "      <td>0.795798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.758435</td>\n",
              "      <td>0.498047</td>\n",
              "      <td>0.722853</td>\n",
              "      <td>0.639597</td>\n",
              "      <td>0.744929</td>\n",
              "      <td>0.752981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.820489</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.813542</td>\n",
              "      <td>0.779186</td>\n",
              "      <td>0.754994</td>\n",
              "      <td>0.800032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.816791</td>\n",
              "      <td>0.528439</td>\n",
              "      <td>0.768849</td>\n",
              "      <td>0.718986</td>\n",
              "      <td>0.748617</td>\n",
              "      <td>0.734321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.819428</td>\n",
              "      <td>0.539740</td>\n",
              "      <td>0.787029</td>\n",
              "      <td>0.645793</td>\n",
              "      <td>0.791999</td>\n",
              "      <td>0.808847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              logit_cv     logit  lightbm_cv   lightbm    mlp_cv       mlp\n",
              "category                                                                  \n",
              "games         0.903527  0.806944    0.912480  0.919544  0.886719  0.906730\n",
              "exchanges     0.959379  0.899540    0.955496  0.937949  0.946653  0.961716\n",
              "finance       0.904681  0.738059    0.908626  0.892642  0.875982  0.864202\n",
              "gambling      0.887796  0.738960    0.900053  0.835281  0.888690  0.880790\n",
              "others        0.845451  0.531337    0.839435  0.784331  0.818368  0.799468\n",
              "high-risk     0.905216  0.694668    0.896943  0.884201  0.864426  0.932557\n",
              "marketplaces  0.774803  0.595238    0.754351  0.759150  0.764272  0.795798\n",
              "social        0.758435  0.498047    0.722853  0.639597  0.744929  0.752981\n",
              "development   0.820489  0.583333    0.813542  0.779186  0.754994  0.800032\n",
              "media         0.816791  0.528439    0.768849  0.718986  0.748617  0.734321\n",
              "property      0.819428  0.539740    0.787029  0.645793  0.791999  0.808847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzVLXqr6IXqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUxtgjlTIR4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RL_C3gAIR2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BRYoh7TYsiq",
        "colab_type": "text"
      },
      "source": [
        "# Sequential Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlMQ0_DfueAO",
        "colab_type": "text"
      },
      "source": [
        "## Word-to-Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN0eP1yvPDJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIpWBwFLMN4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check out the first 20 comments as a sample for tokenizing\n",
        "regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "corpus = ' '.join(X_train[0:20]['comments'].values)\n",
        "new_words = regex_tokenizer.tokenize(corpus)\n",
        "\n",
        "new_words = sum([word.split('_') for word in new_words],[])\n",
        "new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words] #split cramelCase\n",
        "new_words = sum(new_words, [])\n",
        "\n",
        "fdist1 = nltk.FreqDist(new_words)\n",
        "fdist1.most_common(50)\n",
        "#len(np.unique(new_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViLcEqzcJY5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check out the first 20 codes as a sample for tokenizing\n",
        "\n",
        "corpus = ' '.join(X_train[0:20]['uncommented'].values)\n",
        "new_words = nltk.word_tokenize(corpus)\n",
        "\n",
        "#new_words = sum([word.split('_') for word in new_words],[])\n",
        "#new_words = [re.sub('[0-9]','', word) for word in new_words]\n",
        "new_words = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in new_words]\n",
        "new_words = sum(new_words, [])\n",
        "\n",
        "fdist1 = nltk.FreqDist(new_words)\n",
        "fdist1.most_common(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJ6nQ6beoWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define tokenizer that's fit for comments\n",
        "def build_corpus_comments (list_of_text):\n",
        "\n",
        "  corpus = []\n",
        "\n",
        "  regex_tokenizer = nltk.RegexpTokenizer(r\"[\\w^@]+\")\n",
        "  my_stopwords = stopwords.words(\"english\")\n",
        "  my_stopwords.append(\"\")\n",
        "\n",
        "  for i in range(0,len(list_of_text)):\n",
        "    text = list_of_text[i]\n",
        "    text = regex_tokenizer.tokenize(text)\n",
        "    text = sum([word.split('_') for word in text],[])\n",
        "    text = [re.sub('[0-9]','', word) for word in text]\n",
        "    text = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in text]\n",
        "    text = sum(text, [])\n",
        "\n",
        "    text = [w for w in text if not w in my_stopwords]\n",
        "    corpus.append(text)\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1deFVmnRavk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define tokenizer that's fit for codes\n",
        "def build_corpus_codes (codes):\n",
        "  corpus = []\n",
        "  my_stopwords = stopwords.words(\"english\")\n",
        "  my_stopwords.append(\"\")\n",
        "  \n",
        "  for i in range(0,len(codes)):\n",
        "    text = codes[i]\n",
        "    text = nltk.word_tokenize(text)\n",
        "    text = sum([word.split('_') for word in text],[])\n",
        "    text = [re.sub('[0-9]','', word) for word in text]\n",
        "    text = [re.sub('([A-Z][a-z]+)',r' \\1',re.sub('([A-Z]+)',r' \\1', word)).split() for word in text]\n",
        "    text = sum(text, [])\n",
        "    text = [w for w in text if not w in my_stopwords]\n",
        "    corpus.append(text)\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHyA_nw9rVVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build corpus base on the comments\n",
        "comments_train_corpus = build_corpus_comments(X_train['comments'].values)\n",
        "comments_test_corpus = build_corpus_comments(X_test['comments'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xCJcGlSJqlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build corpus base on the codes\n",
        "codes_train_corpus = build_corpus_codes(X_train['uncommented'].values)\n",
        "codes_test_corpus = build_corpus_codes(X_test['uncommented'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfnF2Y2uNl4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize but check if the num_words makes sense from the vocal sizes in the subsequent code blocks\n",
        "num_words=5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCmS7BXO6RG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5886c255-9b4c-4293-8180-990bfa649106"
      },
      "source": [
        "# tokenize_to_seq comments\n",
        "tokenizer_obj=Tokenizer(num_words=num_words, lower=True)\n",
        "tokenizer_obj.fit_on_texts(comments_train_corpus)\n",
        "comments_train_seq=tokenizer_obj.texts_to_sequences(comments_train_corpus)\n",
        "comments_test_seq=tokenizer_obj.texts_to_sequences(comments_test_corpus)\n",
        "len(tokenizer_obj.word_index)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11970"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7RODnzZKOx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44ae2301-2a8d-44de-b74e-e38a65891e53"
      },
      "source": [
        "# tokenize_to_seq codes\n",
        "tokenizer_obj=Tokenizer(num_words=num_words, lower=True)\n",
        "tokenizer_obj.fit_on_texts(codes_train_corpus)\n",
        "codes_train_seq=tokenizer_obj.texts_to_sequences(codes_train_corpus)\n",
        "codes_test_seq=tokenizer_obj.texts_to_sequences(codes_test_corpus)\n",
        "len(tokenizer_obj.word_index)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23039"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgyojuMcZbph",
        "colab_type": "code",
        "outputId": "00d09705-6b8e-4af5-ac14-cff7982a7efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# set maxlen to be padded based on text length after tokenization\n",
        "comment_len = [len(comments) for comments in comments_train_seq]\n",
        "code_len = [len(codes) for codes in codes_train_seq]\n",
        "\n",
        "maxlen = 5000\n",
        "(np.mean(comment_len)+1*np.std(comment_len), np.mean(code_len)+1*np.std(code_len)),(max(comment_len),max(code_len))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2187.261740096789, 6438.595270490277), (8452, 38090))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6jrp96CTKab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad\n",
        "comments_train_seq=pad_sequences(comments_train_seq,maxlen=maxlen)\n",
        "comments_test_seq=pad_sequences(comments_test_seq,maxlen=maxlen)\n",
        "\n",
        "codes_train_seq=pad_sequences(codes_train_seq,maxlen=maxlen)\n",
        "codes_test_seq=pad_sequences(codes_test_seq,maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgR7R9ywvdW6",
        "colab_type": "text"
      },
      "source": [
        "### Alternative Pre-trained Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9GyO163ZnR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBNYwkn9se7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download the pre-trained weights\n",
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zodYvSBitFYm",
        "colab_type": "code",
        "outputId": "55510366-3f4e-4501-d38d-0ae6cfb43033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# store it in the W2V format\n",
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "googlenews_w2v = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZexf6dvv08t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the W2V weight matrix\n",
        "googlenews_w2v_matrix = np.zeros((len(word_index) + 1, 300))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Oi6Czv5zF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the vocabulary\n",
        "key = list(googlenews_w2v.vocab.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-5TOO3wKOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fill in the W2V weight matrix\n",
        "for word,i in word_index.items():\n",
        "  if word in key:\n",
        "    googlenews_w2v_matrix[i] = googlenews_w2v.get_vector(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2mb2K18XMgB",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3TIUkbKisMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling1D, MaxPooling2D, Flatten, Input, Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KRM6nw0pnLA",
        "colab_type": "text"
      },
      "source": [
        "define models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQAQsbCEXuQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_GRU (optimizer='adam', GRU_size=128, dropout=0.2):\n",
        "  initializer=keras.initializers.he_normal()\n",
        "\n",
        "  input_NLP = Input(shape=(maxlen,))\n",
        "  embedding_layer = Embedding(input_dim=num_words,output_dim=100,input_length=maxlen,trainable=True)\n",
        "  RNN = embedding_layer(input_NLP)\n",
        "  RNN = GRU(GRU_size,activation='tanh')(RNN)\n",
        "  RNN = Dropout(dropout)(RNN)\n",
        "  RNN = Dense(32,activation='tanh',kernel_initializer=initializer)(RNN)\n",
        "  RNN = Dropout(dropout)(RNN)\n",
        "  predictions = Dense(11,activation='softmax',kernel_initializer=initializer)(RNN)\n",
        "  RNN = Model(inputs=input_NLP, outputs=predictions)\n",
        "  RNN.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "  return RNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ptgDYhbr-5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_CNN (optimizer='adam', filter_size=64, kernel_size=3, dropout=0.2):\n",
        "  initializer=keras.initializers.he_normal()\n",
        "\n",
        "  input_NLP = Input(shape=(maxlen,))\n",
        "  embedding_layer = Embedding(input_dim=num_words,output_dim=100,input_length=maxlen,trainable=True)\n",
        "  CNN = embedding_layer(input_NLP)\n",
        "  CNN = Dropout(dropout)(CNN)\n",
        "  CNN = Conv1D(filters=filter_size,kernel_size=kernel_size,padding='valid',activation='relu')(CNN)\n",
        "  CNN = GlobalMaxPooling1D()(CNN)\n",
        "  CNN = Dropout(dropout)(CNN)\n",
        "  CNN = Dense(32,activation='relu',kernel_initializer=initializer)(CNN)\n",
        "  CNN = Dropout(dropout)(CNN)\n",
        "  predictions = Dense(11,activation='softmax',kernel_initializer=initializer)(CNN)\n",
        "  CNN = Model(inputs=input_NLP, outputs=predictions)\n",
        "  CNN.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "  return CNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJRXlBmq8FV",
        "colab_type": "text"
      },
      "source": [
        "Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWq83AC2YsLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_seq = comments_train_seq\n",
        "X_test_seq = comments_test_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB92fzDDv91B",
        "colab_type": "code",
        "outputId": "df1a293a-c2a6-423b-bc8f-264b68a56311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# validate again with AUC scoring\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "i = 0\n",
        "val_auc = {'GRU':[[],[],[]],'CNN':[[],[],[]]} #initiate a matrix to save cv auc scores\n",
        "\n",
        "for train_index, val_index in skf.split(X_train_seq, np.array(Y_train).argmax(1)):\n",
        "  CV_X_train = X_train_seq[train_index]\n",
        "  CV_Y_train = np.array(Y_train)[train_index]\n",
        "  CV_X_val = X_train_seq[val_index]\n",
        "  CV_Y_val = np.array(Y_train)[val_index]\n",
        "  Y_val = pd.DataFrame(CV_Y_val,columns=Y_train.columns)\n",
        "  \n",
        "  cb=EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=2, restore_best_weights=True)\n",
        "\n",
        "  #train GRU\n",
        "  GRU_model = create_GRU()\n",
        "  print(\"\\n\",\"Training for GRU, fold#=\", i+1,\"\\n\")\n",
        "  GRU_model.fit(CV_X_train, CV_Y_train,batch_size=100, epochs=20, verbose=1,validation_data=(CV_X_val,CV_Y_val), callbacks=[cb],shuffle=False)\n",
        "  GRU_pred = GRU_model.predict(CV_X_val)\n",
        "  GRU_pred = pd.DataFrame(GRU_pred,columns=Y_train.columns)\n",
        "  for DApp in Y_train.columns:\n",
        "    val_auc['GRU'][i].append([DApp,roc_auc_score(Y_val[DApp],GRU_pred[DApp])])  \n",
        "\n",
        "  #train CNN\n",
        "  CNN = create_CNN()\n",
        "  print(\"\\n\",\"Training for CNN, fold#=\", i+1,\"\\n\")\n",
        "  CNN.fit(CV_X_train, CV_Y_train,batch_size=100, epochs=20, verbose=1,validation_data=(CV_X_val,CV_Y_val), callbacks=[cb],shuffle=False)\n",
        "  CNN_pred = CNN.predict(CV_X_val)\n",
        "  CNN_pred = pd.DataFrame(CNN_pred,columns=Y_train.columns)\n",
        "  for DApp in Y_train.columns:\n",
        "    val_auc['CNN'][i].append([DApp,roc_auc_score(Y_val[DApp],CNN_pred[DApp])])\n",
        "  \n",
        "  #count add\n",
        "  i=i+1"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Training for GRU, fold#= 1 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/200\n",
            "1062/1062 [==============================] - 206s 194ms/step - loss: 2.3371 - val_loss: 2.2063\n",
            "Epoch 2/200\n",
            "1062/1062 [==============================] - 206s 194ms/step - loss: 2.0721 - val_loss: 1.9434\n",
            "Epoch 3/200\n",
            "1062/1062 [==============================] - 206s 194ms/step - loss: 1.8550 - val_loss: 1.7830\n",
            "Epoch 4/200\n",
            "1062/1062 [==============================] - 204s 192ms/step - loss: 1.6055 - val_loss: 1.6847\n",
            "Epoch 5/200\n",
            "1062/1062 [==============================] - 208s 195ms/step - loss: 1.4143 - val_loss: 1.5861\n",
            "Epoch 6/200\n",
            "1062/1062 [==============================] - 206s 194ms/step - loss: 1.2176 - val_loss: 1.5980\n",
            "Epoch 7/200\n",
            "1062/1062 [==============================] - 208s 196ms/step - loss: 1.0696 - val_loss: 1.5514\n",
            "Epoch 8/200\n",
            "1062/1062 [==============================] - 213s 200ms/step - loss: 0.9512 - val_loss: 1.5956\n",
            "Epoch 9/200\n",
            "1062/1062 [==============================] - 212s 199ms/step - loss: 0.8704 - val_loss: 1.5845\n",
            "\n",
            " Training for CNN, fold#= 1 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 2.3266 - val_loss: 2.1489\n",
            "Epoch 2/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 2.0597 - val_loss: 1.9143\n",
            "Epoch 3/200\n",
            "1062/1062 [==============================] - 25s 23ms/step - loss: 1.8704 - val_loss: 1.7788\n",
            "Epoch 4/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.7695 - val_loss: 1.6945\n",
            "Epoch 5/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.6713 - val_loss: 1.6257\n",
            "Epoch 6/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.5991 - val_loss: 1.5609\n",
            "Epoch 7/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.5157 - val_loss: 1.5049\n",
            "Epoch 8/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.4411 - val_loss: 1.4485\n",
            "Epoch 9/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.3657 - val_loss: 1.3965\n",
            "Epoch 10/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.3026 - val_loss: 1.3536\n",
            "Epoch 11/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.2041 - val_loss: 1.3129\n",
            "Epoch 12/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.1606 - val_loss: 1.2800\n",
            "Epoch 13/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.0648 - val_loss: 1.2498\n",
            "Epoch 14/200\n",
            "1062/1062 [==============================] - 25s 23ms/step - loss: 1.0475 - val_loss: 1.2273\n",
            "Epoch 15/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 0.9719 - val_loss: 1.2088\n",
            "Epoch 16/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.9344 - val_loss: 1.1938\n",
            "Epoch 17/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.8722 - val_loss: 1.1827\n",
            "Epoch 18/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.8413 - val_loss: 1.1681\n",
            "Epoch 19/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.7893 - val_loss: 1.1590\n",
            "Epoch 20/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.7591 - val_loss: 1.1520\n",
            "Epoch 21/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.7441 - val_loss: 1.1494\n",
            "Epoch 22/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6854 - val_loss: 1.1471\n",
            "Epoch 23/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6825 - val_loss: 1.1444\n",
            "Epoch 24/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6390 - val_loss: 1.1481\n",
            "Epoch 25/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6396 - val_loss: 1.1518\n",
            "\n",
            " Training for GRU, fold#= 2 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/200\n",
            "1062/1062 [==============================] - 225s 212ms/step - loss: 2.3407 - val_loss: 2.2400\n",
            "Epoch 2/200\n",
            "1062/1062 [==============================] - 226s 213ms/step - loss: 2.0921 - val_loss: 1.9707\n",
            "Epoch 3/200\n",
            "1062/1062 [==============================] - 223s 210ms/step - loss: 1.8414 - val_loss: 1.7830\n",
            "Epoch 4/200\n",
            "1062/1062 [==============================] - 222s 209ms/step - loss: 1.6001 - val_loss: 1.6680\n",
            "Epoch 5/200\n",
            "1062/1062 [==============================] - 222s 209ms/step - loss: 1.4218 - val_loss: 1.5934\n",
            "Epoch 6/200\n",
            "1062/1062 [==============================] - 221s 208ms/step - loss: 1.2235 - val_loss: 1.5916\n",
            "Epoch 7/200\n",
            "1062/1062 [==============================] - 222s 209ms/step - loss: 1.0595 - val_loss: 1.4957\n",
            "Epoch 8/200\n",
            "1062/1062 [==============================] - 220s 207ms/step - loss: 0.9370 - val_loss: 1.6470\n",
            "Epoch 9/200\n",
            "1062/1062 [==============================] - 217s 205ms/step - loss: 0.8730 - val_loss: 1.5464\n",
            "\n",
            " Training for CNN, fold#= 2 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 2.2208 - val_loss: 2.0966\n",
            "Epoch 2/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 2.0389 - val_loss: 1.9116\n",
            "Epoch 3/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.9096 - val_loss: 1.8124\n",
            "Epoch 4/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.8120 - val_loss: 1.7314\n",
            "Epoch 5/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.7364 - val_loss: 1.6625\n",
            "Epoch 6/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.6606 - val_loss: 1.6007\n",
            "Epoch 7/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.5815 - val_loss: 1.5392\n",
            "Epoch 8/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.5127 - val_loss: 1.4834\n",
            "Epoch 9/200\n",
            "1062/1062 [==============================] - 25s 24ms/step - loss: 1.4310 - val_loss: 1.4312\n",
            "Epoch 10/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.3484 - val_loss: 1.3843\n",
            "Epoch 11/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.3229 - val_loss: 1.3451\n",
            "Epoch 12/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.2450 - val_loss: 1.3082\n",
            "Epoch 13/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.1952 - val_loss: 1.2760\n",
            "Epoch 14/200\n",
            "1062/1062 [==============================] - 27s 25ms/step - loss: 1.1123 - val_loss: 1.2469\n",
            "Epoch 15/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.0743 - val_loss: 1.2208\n",
            "Epoch 16/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.0400 - val_loss: 1.1966\n",
            "Epoch 17/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.9959 - val_loss: 1.1758\n",
            "Epoch 18/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.9568 - val_loss: 1.1593\n",
            "Epoch 19/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.8993 - val_loss: 1.1454\n",
            "Epoch 20/200\n",
            "1062/1062 [==============================] - 27s 25ms/step - loss: 0.8818 - val_loss: 1.1336\n",
            "Epoch 21/200\n",
            "1062/1062 [==============================] - 27s 25ms/step - loss: 0.8213 - val_loss: 1.1243\n",
            "Epoch 22/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.7991 - val_loss: 1.1146\n",
            "Epoch 23/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.7720 - val_loss: 1.1077\n",
            "Epoch 24/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.7477 - val_loss: 1.0978\n",
            "Epoch 25/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.7164 - val_loss: 1.0876\n",
            "Epoch 26/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.7285 - val_loss: 1.0828\n",
            "Epoch 27/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6964 - val_loss: 1.0757\n",
            "Epoch 28/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6245 - val_loss: 1.0710\n",
            "Epoch 29/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6256 - val_loss: 1.0711\n",
            "Epoch 30/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 0.6114 - val_loss: 1.0744\n",
            "\n",
            " Training for GRU, fold#= 3 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/200\n",
            "1062/1062 [==============================] - 218s 206ms/step - loss: 2.3203 - val_loss: 2.1836\n",
            "Epoch 2/200\n",
            "1062/1062 [==============================] - 219s 206ms/step - loss: 2.0375 - val_loss: 1.9226\n",
            "Epoch 3/200\n",
            "1062/1062 [==============================] - 217s 205ms/step - loss: 1.7945 - val_loss: 1.7825\n",
            "Epoch 4/200\n",
            "1062/1062 [==============================] - 217s 204ms/step - loss: 1.5466 - val_loss: 1.7286\n",
            "Epoch 5/200\n",
            "1062/1062 [==============================] - 218s 205ms/step - loss: 1.3165 - val_loss: 1.7843\n",
            "Epoch 6/200\n",
            "1062/1062 [==============================] - 219s 206ms/step - loss: 1.1564 - val_loss: 1.6919\n",
            "Epoch 7/200\n",
            "1062/1062 [==============================] - 218s 205ms/step - loss: 0.9935 - val_loss: 1.6692\n",
            "Epoch 8/200\n",
            "1062/1062 [==============================] - 218s 205ms/step - loss: 0.8797 - val_loss: 1.7181\n",
            "Epoch 9/200\n",
            "1062/1062 [==============================] - 220s 207ms/step - loss: 0.7915 - val_loss: 1.7735\n",
            "\n",
            " Training for CNN, fold#= 3 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1062 samples, validate on 531 samples\n",
            "Epoch 1/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 2.3069 - val_loss: 2.2177\n",
            "Epoch 2/200\n",
            "1062/1062 [==============================] - 27s 25ms/step - loss: 2.1384 - val_loss: 2.0698\n",
            "Epoch 3/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 2.0053 - val_loss: 1.9367\n",
            "Epoch 4/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.8870 - val_loss: 1.8269\n",
            "Epoch 5/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.7660 - val_loss: 1.7455\n",
            "Epoch 6/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.6907 - val_loss: 1.6834\n",
            "Epoch 7/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.6094 - val_loss: 1.6307\n",
            "Epoch 8/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.5431 - val_loss: 1.5836\n",
            "Epoch 9/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.4574 - val_loss: 1.5430\n",
            "Epoch 10/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.3922 - val_loss: 1.5019\n",
            "Epoch 11/200\n",
            "1062/1062 [==============================] - 28s 26ms/step - loss: 1.3256 - val_loss: 1.4653\n",
            "Epoch 12/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.2702 - val_loss: 1.4375\n",
            "Epoch 13/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.2149 - val_loss: 1.4122\n",
            "Epoch 14/200\n",
            "1062/1062 [==============================] - 26s 24ms/step - loss: 1.1626 - val_loss: 1.3928\n",
            "Epoch 15/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.1036 - val_loss: 1.3755\n",
            "Epoch 16/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.0486 - val_loss: 1.3563\n",
            "Epoch 17/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 1.0118 - val_loss: 1.3439\n",
            "Epoch 18/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.9439 - val_loss: 1.3335\n",
            "Epoch 19/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.9283 - val_loss: 1.3258\n",
            "Epoch 20/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.8777 - val_loss: 1.3147\n",
            "Epoch 21/200\n",
            "1062/1062 [==============================] - 27s 25ms/step - loss: 0.8553 - val_loss: 1.3068\n",
            "Epoch 22/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.7835 - val_loss: 1.2989\n",
            "Epoch 23/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.7840 - val_loss: 1.2943\n",
            "Epoch 24/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.7480 - val_loss: 1.2859\n",
            "Epoch 25/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.6916 - val_loss: 1.2828\n",
            "Epoch 26/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.6632 - val_loss: 1.2842\n",
            "Epoch 27/200\n",
            "1062/1062 [==============================] - 26s 25ms/step - loss: 0.6448 - val_loss: 1.2761\n",
            "Epoch 28/200\n",
            "1062/1062 [==============================] - 27s 25ms/step - loss: 0.6141 - val_loss: 1.2780\n",
            "Epoch 29/200\n",
            "1062/1062 [==============================] - 27s 25ms/step - loss: 0.6039 - val_loss: 1.2885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1FcJNNyIREU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('cv.pickle', 'wb') as handle:\n",
        "  pickle.dump(val_auc, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "485Rd0efdN68",
        "colab_type": "text"
      },
      "source": [
        "Optional: save cv results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y__qqFJau6hJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1bc2241-8bd8-4f0c-b3c6-c309c1ee777c"
      },
      "source": [
        "val_auc"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CNN': [[['development', 0.8778427550357375],\n",
              "   ['exchanges', 0.9747909698996655],\n",
              "   ['finance', 0.9243088425129088],\n",
              "   ['gambling', 0.8613557456177492],\n",
              "   ['games', 0.9237077355634058],\n",
              "   ['high-risk', 0.9077909270216962],\n",
              "   ['marketplaces', 0.8775910364145658],\n",
              "   ['media', 0.7992718446601942],\n",
              "   ['others', 0.8604890781700782],\n",
              "   ['property', 0.8206118206118206],\n",
              "   ['social', 0.8373776908023484]],\n",
              "  [['development', 0.9459830624856947],\n",
              "   ['exchanges', 0.9608734065379275],\n",
              "   ['finance', 0.9380782056798623],\n",
              "   ['gambling', 0.9148856548856549],\n",
              "   ['games', 0.9477687261192416],\n",
              "   ['high-risk', 0.9043392504930967],\n",
              "   ['marketplaces', 0.8476190476190476],\n",
              "   ['media', 0.872281986724651],\n",
              "   ['others', 0.8850632069194944],\n",
              "   ['property', 0.8003371868978805],\n",
              "   ['social', 0.8321428571428572]],\n",
              "  [['development', 0.7810807883907299],\n",
              "   ['exchanges', 0.9584448160535117],\n",
              "   ['finance', 0.9038968373493975],\n",
              "   ['gambling', 0.861995841995842],\n",
              "   ['games', 0.9184166696839133],\n",
              "   ['high-risk', 0.8702333990795529],\n",
              "   ['marketplaces', 0.8173679060665362],\n",
              "   ['media', 0.8048180361638819],\n",
              "   ['others', 0.8037591483699269],\n",
              "   ['property', 0.7866052866052866],\n",
              "   ['social', 0.764905427631579]]],\n",
              " 'GRU': [[['development', 0.7966211825860948],\n",
              "   ['exchanges', 0.9474916387959867],\n",
              "   ['finance', 0.7886053141135972],\n",
              "   ['gambling', 0.8541578457108984],\n",
              "   ['games', 0.8547058611491603],\n",
              "   ['high-risk', 0.6165351742274819],\n",
              "   ['marketplaces', 0.688468720821662],\n",
              "   ['media', 0.7512135922330097],\n",
              "   ['others', 0.7022255804368732],\n",
              "   ['property', 0.8271458271458272],\n",
              "   ['social', 0.7257338551859099]],\n",
              "  [['development', 0.808194094758526],\n",
              "   ['exchanges', 0.9291934873154108],\n",
              "   ['finance', 0.803154582616179],\n",
              "   ['gambling', 0.8255509355509355],\n",
              "   ['games', 0.871125009011607],\n",
              "   ['high-risk', 0.8529339250493096],\n",
              "   ['marketplaces', 0.7121848739495799],\n",
              "   ['media', 0.7859922178988328],\n",
              "   ['others', 0.7341982701264138],\n",
              "   ['property', 0.7227842003853564],\n",
              "   ['social', 0.6909491193737769]],\n",
              "  [['development', 0.7111219406541044],\n",
              "   ['exchanges', 0.923651755852843],\n",
              "   ['finance', 0.8029125430292599],\n",
              "   ['gambling', 0.8132848232848232],\n",
              "   ['games', 0.792000072413918],\n",
              "   ['high-risk', 0.6928418803418803],\n",
              "   ['marketplaces', 0.7250978473581213],\n",
              "   ['media', 0.7157816433966583],\n",
              "   ['others', 0.6971723220226216],\n",
              "   ['property', 0.7304722304722304],\n",
              "   ['social', 0.6408305921052632]]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9726f8fypdxV",
        "colab_type": "code",
        "outputId": "64eae4ab-896f-44b6-ef6f-c57afdfbb4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# output the average AUC score\n",
        "AUC = val_auc['GRU']\n",
        "cv = pd.concat([pd.DataFrame(AUC[0],columns=['categories','AUC']),pd.DataFrame(AUC[1],columns=['categories','AUC']),pd.DataFrame(AUC[2],columns=['categories','AUC'])]).groupby('categories').mean()\n",
        "cv = cv.loc[data['category'].value_counts().index,:]\n",
        "cv['AUC'].values"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83927698, 0.93344563, 0.79822415, 0.83099787, 0.71119872,\n",
              "       0.72077033, 0.70858381, 0.68583786, 0.77197907, 0.75099582,\n",
              "       0.76013409])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HTgcYRPdhJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93f7eaf8-a36c-407e-fc53-73b5bafb726d"
      },
      "source": [
        "cv['AUC'].values.mean()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7737676654355803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kQXnxLGMJ_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6974dcdf-2b65-438f-80a0-5af64dcffe7b"
      },
      "source": [
        "cv_result.loc[(cv_result['models']=='GRU') & (cv_result['input_types']=='comments_only'),'AUC']"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33   NaN\n",
              "34   NaN\n",
              "35   NaN\n",
              "36   NaN\n",
              "37   NaN\n",
              "38   NaN\n",
              "39   NaN\n",
              "40   NaN\n",
              "41   NaN\n",
              "42   NaN\n",
              "43   NaN\n",
              "Name: AUC, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbRgP2YDn2uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# update validation results\n",
        "cv_result.loc[(cv_result['models']=='GRU') & (cv_result['input_types']=='comments_only'),('AUC')] = cv['AUC'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv5_8h4hvLj-",
        "colab_type": "text"
      },
      "source": [
        "## train the model and run on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18XplphHyW2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb=EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=2, restore_best_weights=True)\n",
        "\n",
        "model.fit(W2V_train_seq, np.array(Y_train),\n",
        "      batch_size=50, epochs=200, verbose=1,\n",
        "      #validation_data=(X_test, y_test.reshape(-1,y_test.shape[1])),\n",
        "      validation_split=0.25,\n",
        "      callbacks=[cb],shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKgrbM0pafH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = model.predict(W2V_test_seq)\n",
        "Y_pred = pd.DataFrame(Y_pred,columns=Y_train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFSpfni8bbap",
        "colab_type": "code",
        "outputId": "5ab050c8-e6d4-4c9d-b28a-7f8da5199ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "table = []\n",
        "for DApp in Y_train.columns:\n",
        "  table.append([DApp,roc_auc_score(Y_test[DApp],Y_pred[DApp])])\n",
        "\n",
        "table = pd.DataFrame(table)\n",
        "table.columns = ['category','CNN']\n",
        "table.set_index('category',inplace=True)\n",
        "table.loc[data['category'].value_counts().index,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>0.580347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exchanges</th>\n",
              "      <td>0.734187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>finance</th>\n",
              "      <td>0.557202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gambling</th>\n",
              "      <td>0.670520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td>0.554724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high-risk</th>\n",
              "      <td>0.416338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketplaces</th>\n",
              "      <td>0.532400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>social</th>\n",
              "      <td>0.635588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>development</th>\n",
              "      <td>0.447206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media</th>\n",
              "      <td>0.556311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>0.511400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   CNN\n",
              "games         0.580347\n",
              "exchanges     0.734187\n",
              "finance       0.557202\n",
              "gambling      0.670520\n",
              "others        0.554724\n",
              "high-risk     0.416338\n",
              "marketplaces  0.532400\n",
              "social        0.635588\n",
              "development   0.447206\n",
              "media         0.556311\n",
              "property      0.511400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o3XdVRmcWJm",
        "colab_type": "text"
      },
      "source": [
        "# Present the cv and the test table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kRft3QXGlNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "order = data['category'].value_counts().index.values.tolist()\n",
        "order = [('AUC',x) for x in order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8oQ9f_6EjQT",
        "colab_type": "code",
        "outputId": "9e8355de-b344-4667-d12e-8e3497de9a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      },
      "source": [
        "cv_result.set_index(keys=['input_types','models','categories']).unstack('categories').loc[:,order]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"11\" halign=\"left\">AUC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>games</th>\n",
              "      <th>exchanges</th>\n",
              "      <th>finance</th>\n",
              "      <th>gambling</th>\n",
              "      <th>others</th>\n",
              "      <th>high-risk</th>\n",
              "      <th>marketplaces</th>\n",
              "      <th>social</th>\n",
              "      <th>development</th>\n",
              "      <th>media</th>\n",
              "      <th>property</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>input_types</th>\n",
              "      <th>models</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">codes_only</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.940143</td>\n",
              "      <td>0.966873</td>\n",
              "      <td>0.932744</td>\n",
              "      <td>0.933317</td>\n",
              "      <td>0.851067</td>\n",
              "      <td>0.915680</td>\n",
              "      <td>0.842207</td>\n",
              "      <td>0.843397</td>\n",
              "      <td>0.885706</td>\n",
              "      <td>0.833062</td>\n",
              "      <td>0.847884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.633049</td>\n",
              "      <td>0.883496</td>\n",
              "      <td>0.655510</td>\n",
              "      <td>0.689534</td>\n",
              "      <td>0.631175</td>\n",
              "      <td>0.557720</td>\n",
              "      <td>0.585778</td>\n",
              "      <td>0.682109</td>\n",
              "      <td>0.674383</td>\n",
              "      <td>0.671397</td>\n",
              "      <td>0.699580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">combined</th>\n",
              "      <th>CNN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">comments_only</th>\n",
              "      <th>CNN</th>\n",
              "      <td>0.929964</td>\n",
              "      <td>0.964703</td>\n",
              "      <td>0.922095</td>\n",
              "      <td>0.879412</td>\n",
              "      <td>0.849770</td>\n",
              "      <td>0.894121</td>\n",
              "      <td>0.847526</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.868302</td>\n",
              "      <td>0.825457</td>\n",
              "      <td>0.802518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.839277</td>\n",
              "      <td>0.933446</td>\n",
              "      <td>0.798224</td>\n",
              "      <td>0.830998</td>\n",
              "      <td>0.711199</td>\n",
              "      <td>0.720770</td>\n",
              "      <td>0.708584</td>\n",
              "      <td>0.685838</td>\n",
              "      <td>0.771979</td>\n",
              "      <td>0.750996</td>\n",
              "      <td>0.760134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            AUC            ...                    \n",
              "categories                games exchanges  ...     media  property\n",
              "input_types   models                       ...                    \n",
              "codes_only    CNN      0.940143  0.966873  ...  0.833062  0.847884\n",
              "              GRU      0.633049  0.883496  ...  0.671397  0.699580\n",
              "              lightbm       NaN       NaN  ...       NaN       NaN\n",
              "              logit         NaN       NaN  ...       NaN       NaN\n",
              "              mlp           NaN       NaN  ...       NaN       NaN\n",
              "combined      CNN           NaN       NaN  ...       NaN       NaN\n",
              "              GRU           NaN       NaN  ...       NaN       NaN\n",
              "              lightbm       NaN       NaN  ...       NaN       NaN\n",
              "              logit         NaN       NaN  ...       NaN       NaN\n",
              "              mlp           NaN       NaN  ...       NaN       NaN\n",
              "comments_only CNN      0.929964  0.964703  ...  0.825457  0.802518\n",
              "              GRU      0.839277  0.933446  ...  0.750996  0.760134\n",
              "              lightbm       NaN       NaN  ...       NaN       NaN\n",
              "              logit         NaN       NaN  ...       NaN       NaN\n",
              "              mlp           NaN       NaN  ...       NaN       NaN\n",
              "\n",
              "[15 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXl9Kg4lca6n",
        "colab_type": "code",
        "outputId": "4939ac3d-7cd9-45bb-b27d-5cf7de41f899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "result.set_index(keys=['input_types','models','categories']).unstack('categories').loc[:,order]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"11\" halign=\"left\">AUC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>games</th>\n",
              "      <th>exchanges</th>\n",
              "      <th>finance</th>\n",
              "      <th>gambling</th>\n",
              "      <th>others</th>\n",
              "      <th>high-risk</th>\n",
              "      <th>marketplaces</th>\n",
              "      <th>social</th>\n",
              "      <th>development</th>\n",
              "      <th>media</th>\n",
              "      <th>property</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>input_types</th>\n",
              "      <th>models</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">codes_only</th>\n",
              "      <th>CNN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">combined</th>\n",
              "      <th>CNN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">comments_only</th>\n",
              "      <th>CNN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightbm</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logit</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        AUC                    ...                           \n",
              "categories            games exchanges finance  ... development media property\n",
              "input_types   models                           ...                           \n",
              "codes_only    CNN       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              GRU       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              lightbm   NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              logit     NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              mlp       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "combined      CNN       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              GRU       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              lightbm   NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              logit     NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              mlp       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "comments_only CNN       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              GRU       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              lightbm   NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              logit     NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "              mlp       NaN       NaN     NaN  ...         NaN   NaN      NaN\n",
              "\n",
              "[15 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pGrcH-Nn-y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.to_csv('test_auc.csv',index=False)\n",
        "cv_result.to_csv('validation_auc.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocfXDh12fchk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}